/**
 * bizinfo.go.kr Detail Page Scraper ‚Äî Integration Test
 *
 * Tests the scraper on 3 real programs with bizinfo.go.kr detailUrl.
 * Validates:
 *   1. ‚â•3/3 detail pages successfully fetched
 *   2. Page text ‚â•500 chars for each (or ‚â•200 chars with relaxed threshold)
 *   3. Î≥∏Î¨∏Ï∂úÎ†•ÌååÏùº download URL found for ‚â•2/3
 *   4. Tags extracted for ‚â•2/3
 *
 * Run: npx tsx scripts/test-bizinfo-scraper.ts
 *   --with-download    Also test Í≥µÍ≥†Î¨∏ download + text extraction
 */

import { PrismaClient } from '@prisma/client';
import { scrapeBizinfoDetailPage, sleep } from '../lib/sme24-api/bizinfo-detail-scraper';

const prisma = new PrismaClient();

interface TestResult {
  programId: string;
  title: string;
  url: string;
  success: boolean;
  pageTextLength: number;
  fieldsCount: number;
  fields: Record<string, string>;
  tagsCount: number;
  tags: string[];
  hasDownloadUrl: boolean;
  downloadUrl: string | null;
  documentFileName: string | null;
  documentTextLength: number;
  error?: string;
}

async function main() {
  const args = process.argv.slice(2);
  const withDownload = args.includes('--with-download');

  console.log('=== bizinfo.go.kr Scraper Integration Test ===\n');
  console.log(`Download Í≥µÍ≥†Î¨∏: ${withDownload}\n`);

  // Select 3 programs with bizinfo.go.kr detailUrl
  const programs = await prisma.sme_programs.findMany({
    where: {
      status: 'ACTIVE',
      detailUrl: { contains: 'bizinfo.go.kr' },
    },
    select: {
      id: true,
      title: true,
      detailUrl: true,
      description: true,
      supportTarget: true,
    },
    take: 3,
    orderBy: { syncedAt: 'desc' },
  });

  if (programs.length < 3) {
    console.log(`‚ö†Ô∏è Only found ${programs.length} programs with bizinfo detailUrl (need 3)`);
    if (programs.length === 0) {
      console.log('‚ùå FAIL ‚Äî No programs with bizinfo.go.kr detailUrl');
      return;
    }
  }

  console.log(`Testing ${programs.length} programs:\n`);

  const results: TestResult[] = [];

  for (let i = 0; i < programs.length; i++) {
    const program = programs[i];
    const shortTitle = program.title.substring(0, 60);
    console.log(`‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
    console.log(`Test ${i + 1}/${programs.length}: ${shortTitle}`);
    console.log(`URL: ${program.detailUrl}`);

    try {
      const result = await scrapeBizinfoDetailPage(
        program.detailUrl!,
        program.id,
        { downloadDocument: withDownload }
      );

      if (result === null) {
        results.push({
          programId: program.id,
          title: shortTitle,
          url: program.detailUrl!,
          success: false,
          pageTextLength: 0,
          fieldsCount: 0,
          fields: {},
          tagsCount: 0,
          tags: [],
          hasDownloadUrl: false,
          downloadUrl: null,
          documentFileName: null,
          documentTextLength: 0,
          error: 'Scrape returned null',
        });
        console.log('‚ùå FAILED ‚Äî Scrape returned null\n');
        continue;
      }

      const testResult: TestResult = {
        programId: program.id,
        title: shortTitle,
        url: program.detailUrl!,
        success: true,
        pageTextLength: result.pageText.length,
        fieldsCount: Object.keys(result.fields).length,
        fields: result.fields,
        tagsCount: result.tags.length,
        tags: result.tags,
        hasDownloadUrl: result.downloadUrl !== null,
        downloadUrl: result.downloadUrl,
        documentFileName: result.documentFileName,
        documentTextLength: result.documentText?.length || 0,
      };

      results.push(testResult);

      // Print detailed results
      console.log(`\n  ‚úÖ Scrape successful!`);
      console.log(`  Page text: ${result.pageText.length} chars`);
      console.log(`  Fields extracted: ${Object.keys(result.fields).length}`);
      Object.entries(result.fields).forEach(([k, v]) => {
        const preview = v.length > 80 ? v.substring(0, 80) + '...' : v;
        console.log(`    ‚Ä¢ ${k}: ${preview}`);
      });
      console.log(`  Tags: ${result.tags.length} ‚Äî ${result.tags.slice(0, 6).join(', ')}`);
      console.log(`  Download URL: ${result.downloadUrl ? '‚úÖ Found' : '‚ùå Not found'}`);
      if (result.downloadUrl) {
        console.log(`    ${result.downloadUrl}`);
      }
      console.log(`  Document filename: ${result.documentFileName || 'N/A'}`);
      if (withDownload && result.documentText) {
        console.log(`  Document text: ${result.documentText.length} chars`);
        console.log(`    Preview: ${result.documentText.substring(0, 100)}...`);
      }

      // Compare with existing API data
      console.log(`\n  --- Comparison with API data ---`);
      const apiDescLen = program.description?.length || 0;
      const apiTargetLen = program.supportTarget?.length || 0;
      console.log(`    API description: ${apiDescLen} chars`);
      console.log(`    API supportTarget: ${apiTargetLen} chars`);
      console.log(`    Scraped page text: ${result.pageText.length} chars`);
      const improvement = apiDescLen > 0
        ? ((result.pageText.length / apiDescLen) * 100).toFixed(0)
        : '‚àû';
      console.log(`    Text ratio (scraped/API): ${improvement}%`);

      console.log('');
    } catch (error: any) {
      results.push({
        programId: program.id,
        title: shortTitle,
        url: program.detailUrl!,
        success: false,
        pageTextLength: 0,
        fieldsCount: 0,
        fields: {},
        tagsCount: 0,
        tags: [],
        hasDownloadUrl: false,
        downloadUrl: null,
        documentFileName: null,
        documentTextLength: 0,
        error: error.message,
      });
      console.log(`‚ùå FAILED ‚Äî ${error.message}\n`);
    }

    // Rate limiting between tests
    if (i < programs.length - 1) {
      await sleep(1000);
    }
  }

  // ============================================================================
  // Acceptance Criteria Evaluation
  // ============================================================================

  console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
  console.log('=== Acceptance Criteria ===\n');

  const successful = results.filter((r) => r.success);
  const withGoodText = results.filter((r) => r.pageTextLength >= 200);
  const withDownloadUrl = results.filter((r) => r.hasDownloadUrl);
  const withTags = results.filter((r) => r.tagsCount > 0);

  const criteria = [
    {
      name: '‚â•3/3 detail pages successfully fetched',
      pass: successful.length >= 3,
      detail: `${successful.length}/3`,
    },
    {
      name: 'Page text ‚â•200 chars for each',
      pass: withGoodText.length >= 3,
      detail: `${withGoodText.length}/3 (${results.map((r) => r.pageTextLength).join(', ')} chars)`,
    },
    {
      name: 'Î≥∏Î¨∏Ï∂úÎ†•ÌååÏùº download URL found for ‚â•2/3',
      pass: withDownloadUrl.length >= 2,
      detail: `${withDownloadUrl.length}/3`,
    },
    {
      name: 'Tags extracted for ‚â•2/3',
      pass: withTags.length >= 2,
      detail: `${withTags.length}/3 (${results.map((r) => r.tagsCount).join(', ')} tags)`,
    },
  ];

  let allPass = true;
  for (const c of criteria) {
    const icon = c.pass ? '‚úÖ' : '‚ùå';
    console.log(`  ${icon} ${c.name} ‚Äî ${c.detail}`);
    if (!c.pass) allPass = false;
  }

  console.log(`\n${allPass ? 'üéâ ALL CRITERIA PASSED' : '‚ö†Ô∏è SOME CRITERIA FAILED'}`);
  console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
}

main()
  .catch(console.error)
  .finally(() => prisma.$disconnect());
