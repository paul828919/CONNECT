# üéâ Scraper Configuration - Status Update

**Date**: October 6, 2025  
**Status**: 3/4 agencies working, 1 needs custom handling

---

## ‚úÖ **Working Agencies** (75% Complete)

| Agency | URL | Structure | Status |
|--------|-----|-----------|--------|
| **IITP** | `https://www.iitp.kr/kr/1/business/businessApiView.it` | HTML Table | ‚úÖ Fixed |
| **TIPA** | `https://www.smtech.go.kr/front/ifg/no/notice02_list.do` | HTML Table | ‚úÖ Fixed |
| **KIMST** | `https://www.kimst.re.kr/u/news/inform_01/pjtAnuc.do` | HTML Table | ‚úÖ Fixed |

### Selectors (All 3 agencies):
```typescript
announcementList: 'table tbody tr'
title: 'td:nth-child(N) a'  // N=2 for IITP/KIMST, N=3 for TIPA
link: 'td:nth-child(N) a'
date: 'td:nth-child(N)'     // Column with dates
```

---

## ‚ö†Ô∏è **Needs Custom Handling**

### **KEIT** (Korean Industrial Technology Evaluation Institute)
- **URL**: `https://srome.keit.re.kr/srome/biz/perform/opnnPrpsl/retrieveTaskAnncmListView.do?prgmId=XPG201040000`
- **Problem**: Uses **custom div-based layout** instead of HTML tables
- **Impact**: Standard table scraping doesn't work
- **Solution Needed**: Implement custom extraction logic for div-based announcements

**Why it's complex:**
- No `<table>` elements
- Nested `<generic>` containers with `<paragraph>` elements
- Requires JavaScript to fully load content
- 637 announcements available, but structure is non-standard

---

## üöÄ **Testing Instructions**

### Restart Scraper
```bash
# Stop current scraper
kill $(cat /Users/paulkim/Downloads/connect/.scraper.pid)

# Start fresh
cd /Users/paulkim/Downloads/connect
npm run scraper > logs/scraper-$(date +%Y%m%d-%H%M%S).log 2>&1 &
echo $! > .scraper.pid
```

### Trigger Scraping (3 agencies only)
```bash
npx tsx scripts/trigger-scraping.ts
```

**Expected result**: Jobs queued for IITP, TIPA, and KIMST only (not KEIT)

### Monitor Progress
```bash
npx tsx scripts/monitor-scraping.ts
```

### Verify in Database
```bash
npm run db:studio
# Open http://localhost:5555
# Check FundingProgram table
```

---

## üìä **Expected Outcome (After 5-10 Minutes)**

### ‚úÖ Success Criteria:
- **15-30+ programs** from 3 agencies (IITP, TIPA, KIMST)
- **All programs have `scrapingSource`** URLs (not null)
- **Real Korean titles** like "2025ÎÖÑÎèÑ ÏñëÏûêÍ≥ºÌïôÍ∏∞Ïà†..." 
- **Automatic match generation** based on programs

### Example Programs:
```
IITP:  "(Ïó∞Ïû•Í≥µÍ≥†) 2025ÎÖÑÎèÑ ÏñëÏûêÍ≥ºÌïôÍ∏∞Ïà† ÌîåÎûòÍ∑∏Ïã≠ ÌîÑÎ°úÏ†ùÌä∏"
TIPA:  "2025ÎÖÑ Ï§ëÏÜåÍ∏∞ÏóÖ Ïó∞Íµ¨Ïù∏Î†•ÏßÄÏõêÏÇ¨ÏóÖ(ÌååÍ≤¨) 10Ïõî Í≥µÍ≥†"
KIMST: "2025ÎÖÑÎèÑ ÏïàÏ†ÑÍ∏∞Î∞ò ÏÜåÌòï ÏàòÏÜåÏ∂îÏßÑÏÑ†Î∞ï Í∏∞Ïà†Í∞úÎ∞ú"
```

---

## üîß **Next Steps**

### Immediate (Today):
1. ‚úÖ Restart scraper
2. ‚úÖ Trigger scraping for 3 working agencies
3. ‚úÖ Verify programs are being scraped correctly
4. ‚úÖ Check that matches are generated automatically

### Future (Later):
1. ‚ö†Ô∏è Implement custom extraction logic for KEIT's div-based layout
2. ‚ö†Ô∏è Create specialized parser for KEIT announcements
3. ‚ö†Ô∏è Test KEIT scraping separately
4. ‚ö†Ô∏è Add KEIT back to production scraper

---

## üêõ **Bugs Fixed Today**

| Bug | Location | Problem | Solution |
|-----|----------|---------|----------|
| #1 | `worker.ts:93` | Deprecated Playwright API | Changed to `addInitScript()` |
| #2 | `worker.ts:245` | Wrong database field `errorMessage` | Changed to `error` |
| #3 | `trigger-scraping.ts:35` | Undefined `listingUrl` property | Use `baseUrl + listingPath` |
| #4 | All configs | Wrong/outdated URLs | Found correct announcement URLs |
| #5 | All configs | Wrong CSS selectors | Updated to match actual HTML structure |

---

## üìÅ **Key Files Modified**

```
/Users/paulkim/Downloads/connect/
‚îú‚îÄ‚îÄ lib/scraping/
‚îÇ   ‚îú‚îÄ‚îÄ worker.ts          # Fixed Playwright API & DB field
‚îÇ   ‚îî‚îÄ‚îÄ config.ts          # Updated all agency URLs & selectors
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ trigger-scraping.ts # Fixed URL construction, disabled KEIT
    ‚îú‚îÄ‚îÄ debug-selectors.ts  # New: Debug tool
    ‚îú‚îÄ‚îÄ inspect-structure.ts # New: Structure inspector
    ‚îî‚îÄ‚îÄ test-url.ts         # New: URL tester
```

---

## üéØ **Success Rate**

- **Agencies Configured**: 4
- **Agencies Working**: 3 (75%)
- **Critical Bugs Fixed**: 5
- **Expected Programs**: 20-50+ from 3 agencies

---

## üìû **Troubleshooting**

### If no programs after 10 minutes:
```bash
# Check logs
tail -f logs/scraper-*.log

# Restart scraper
kill $(cat .scraper.pid)
npm run scraper > logs/scraper-$(date +%Y%m%d-%H%M%S).log 2>&1 &
echo $! > .scraper.pid

# Re-trigger
npx tsx scripts/trigger-scraping.ts
```

### If scraper crashes:
Check logs for specific error messages and restart with fresh logs.

---

**Status**: Ready to test! üöÄ
