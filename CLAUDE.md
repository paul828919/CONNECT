# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

---

## ‚ö†Ô∏è CRITICAL WORK RULES - READ FIRST

### 1. Local Verification is MANDATORY

**NEVER commit and push without local verification.**

- **Rule**: When executing any task, ALWAYS verify the work locally upon completion. Only after local verification is complete should you commit and push.
- **Timing**: Deployment to production takes ~12 minutes. Local verification takes 2-5 minutes. Always verify first.
- **Docker requirement**: If Docker is not running locally during development or modification, **tell the user to start Docker**. Never skip local verification just because Docker isn't running.
- **No exceptions**: Even for "simple" changes like config files, YAML syntax, or documentation updates.

**Why this matters:**
- Prevents production failures that take 12+ minutes to discover
- Catches issues in 2-5 minutes locally vs. hours of production debugging
- Industry standard: Local ‚Üí CI ‚Üí Staging ‚Üí Production (NEVER skip local)

### 2. Security: SSH Keys Only

**NEVER use passwords in commands.**

```bash
# ‚úÖ CORRECT - Always use SSH key authentication
ssh -i ~/.ssh/id_ed25519_connect user@221.164.102.253

# ‚ùå WRONG - Never use password authentication
sshpass -p 'password' ssh user@221.164.102.253
```

### 3. üèóÔ∏è CI/CD Architecture (Production-grade entrypoint pattern)

**Status:** ‚úÖ Production-ready (100% successful deployments since October 15, 2025)
**Architecture pattern:** Industry-standard entrypoint

**Changes (October 15, 2025):**
- ‚ùå **Old Method (5 failures)**: External migration orchestration - 200 lines, 7 failure points
- ‚úÖ **New Method (100% success)**: Entrypoint pattern (Heroku/AWS/K8s model) - 50 lines, self-healing

**How it works:**
```
Push to GitHub ‚Üí GitHub Actions trigger Docker build ‚Üí SSH connection to server ‚Üí
Zero-downtime rolling update ‚Üí Migration runs at container startup (entrypoint) ‚Üí
Health check validation ‚Üí Success (or auto-rollback)
```

**Core Files:**
1. `docker-entrypoint.sh` - Runs internal migration at container startup (20 lines)
2. `Dockerfile.production` - Multi-stage build including entrypoint
3. `.github/workflows/deploy-production.yml` - Automated deployment (50 lines)
4. `docker-compose.production.yml` - Orchestration including 90-second health checks

**Core Concepts:**
- **Migration runs inside the container** (not externally via `docker run`)
- **Self-containment**: Each container handles its own initialization
- **Self-healing**: Migration failure = container failure = automatic rollback
- **Atomic verification**: Health checks simultaneously validate migration + application + endpoints

---

## Project Overview

Connect is **Korea's R&D commercialization operating system** that transforms companies' grant-seeking journey from discovery through winning. The platform combines automated matching with professional execution services, targeting companies as primary paying customers (research institutes as supply-side for consortium matching).

**Strategic Positioning:**
- **Not just grant discovery** - Complete commercialization support (discovery ‚Üí application ‚Üí winning)
- **Hybrid business model** - Software (‚Ç©49-99K/month) + Services (‚Ç©2-7M per engagement)
- **Companies first** - 90% revenue from companies, institutes as free supply-side partners
- **Proprietary data moat** - Outcome tracking (win rates, cycle times) creates competitive advantage
- **Profitable Month 1** - Services provide immediate cash flow

**Critical Timeline:**
- MVP Development: 8 weeks (Weeks 1-2: Foundation, Weeks 3-4: Data + Outcomes, Weeks 5-6: Services, Weeks 7-8: Launch)
- Beta Launch: 50 users (45 companies, 5 institutes)
- Public Launch: Target 500 users by Month 4
- Expansion Gate: 1,000 users (if 70%+ retention after 3 months)
- Peak Season: January-March 2025 (99.9% uptime required with hot standby)

## 12-Week Execution Plan (October 9, 2025 ‚Üí January 1, 2026)

**Current Status**: Executing 12-week accelerated plan for January 1, 2026 launch
**Master Plan**: See `docs/plans/EXECUTION-PLAN-MASTER.md` for detailed day-by-day tasks
**Progress Tracking**:
- **Master Tracker**: See `docs/plans/progress/MASTER-PROGRESS-TRACKER.md` (Complete journey Oct 9 ‚Üí Jan 1)
- **Daily Logs**: See `docs/plans/progress/` for individual completion reports
**Quick Status**: See `IMPLEMENTATION-STATUS.md` at project root

**Timeline Overview**:
- **Week 1-2** (Oct 9-22): Hot Standby Infrastructure (PostgreSQL replication, Patroni, HAProxy)
- **Week 3-4** (Oct 23-Nov 5): AI Integration (Claude Sonnet 4.5, match explanations, Q&A chat)
- **Week 5** (Nov 6-12): Comprehensive Load Testing (k6 scenarios, performance optimization)
- **Week 6** (Nov 13-19): Security Hardening & Bug Fixes
- **Week 7** (Nov 20-26): Beta Infrastructure + Internal Testing
- **Week 8** (Nov 27-Dec 3): Beta Week 1 (5-10 companies)
- **Week 9** (Dec 4-10): Beta Week 2 (20-30 companies)
- **Week 10** (Dec 11-17): Beta Week 3 + Code Freeze
- **Week 11** (Dec 18-24): Final Testing + Launch Prep
- **Week 12** (Dec 25-31): Launch Week
- **LAUNCH** (Jan 1, 2026 00:00 KST): Public Launch üöÄ

**Current Week**: See `IMPLEMENTATION-STATUS.md` for real-time status
**Development Tools**: MacBook Pro M4 Max + Claude Code + Claude Desktop

## Commands

```bash
# Development
npm run dev              # Start development server
npm run build           # Build for production
npm run lint            # ESLint checking
npm run type-check      # TypeScript type checking
npm test                # Run unit tests
npm run test:watch      # Run tests in watch mode
npm run test:e2e        # Run Playwright e2e tests

# Database
npm run db:generate     # Generate Prisma client
npm run db:push         # Push schema to database (dev)
npm run db:migrate      # Run database migrations
npm run db:studio       # Open Prisma Studio
npm run db:seed         # Seed database with initial data

# Scraping (Hybrid: NTIS API + Playwright)
npm run scraper:ntis         # NTIS API scraping only
npm run scraper:hybrid       # Both NTIS API + Playwright
npm run scraper:validate     # Validate NTIS integration health
npx tsx scripts/trigger-ntis-scraping.ts        # Manual NTIS trigger
npx tsx scripts/validate-ntis-integration.ts    # Comprehensive validation
npx tsx scripts/test-ntis-simple.ts             # API diagnostics

# Services & Outcomes
npm run outcomes:aggregate   # Calculate aggregate success patterns
npm run services:report      # Generate monthly services revenue report
npm run gates:calculate      # Recalculate sector gate scores (ISMS-P, KC)
npm run procurement:update   # Update procurement readiness scores

# Docker (Production)
# ‚ö†Ô∏è CRITICAL: Always use --platform linux/amd64 for production builds (ARM Mac ‚Üí x86 Linux)
./scripts/build-production-docker.sh        # Recommended: Uses correct platform automatically
docker buildx build --platform linux/amd64 -f Dockerfile.production -t connect:latest .  # Manual build
npm run docker:build    # Build Docker images
npm run docker:up       # Start Docker stack
npm run docker:down     # Stop Docker stack
npm run docker:logs     # View container logs
npm run docker:clean    # Remove containers and volumes

# Deployment
./scripts/deploy.sh           # Zero-downtime Docker deployment
./scripts/rollback.sh         # Emergency rollback
./scripts/backup.sh           # Automated backup
./scripts/health-monitor.sh   # System health monitoring
./scripts/failover.sh         # Hot standby failover (Jan-March)

# GitHub Actions CI/CD (Automated)
git push origin main                      # Triggers automated deployment
./scripts/verify-github-actions.sh        # Verify CI/CD setup
./scripts/test-ssh-connection.sh          # Test SSH connection
./scripts/verify-deployment.sh            # Verify deployment success
```

## GitHub Actions CI/CD (Production Ready)

**Status:** ‚úÖ **Complete** (October 14, 2025)
**Achievement:** 87% faster deployments (35 min ‚Üí 4 min)
**Security:** SSH key authentication (enterprise-grade)

### Automated Deployment Flow

```
git push origin main ‚Üí GitHub Actions ‚Üí Automated Deployment ‚Üí Health Checks ‚Üí Success! ‚ú®
```

**What's Automated:**
- ‚úÖ Build Docker images (with caching)
- ‚úÖ Run tests + linting + security scans
- ‚úÖ Deploy with zero downtime
- ‚úÖ Health checks + automatic rollback
- ‚úÖ Notifications on failure

### Workflows (3)

1. **CI Testing** (`.github/workflows/ci.yml`) - Runs on every PR
   - TypeScript type checking
   - ESLint + Prettier
   - Unit tests (Jest)
   - Security scanning (Trivy, npm audit)
   - Build verification

2. **Production Deployment** (`.github/workflows/deploy-production.yml`) - Runs on push to main
   - Build optimized Docker image
   - SSH to production server (key-based auth)
   - Zero-downtime rolling update
   - Health checks + rollback on failure
   - Duration: 3-4 minutes

3. **PR Preview** (`.github/workflows/preview-deploy.yml`) - Runs on PR
   - Build preview environment
   - Comment deployment status on PR
   - Duration: 2-3 minutes

### Required GitHub Secrets (7)

All secrets documented in `docs/guides/GITHUB-SECRETS-COMPLETE-SETUP.md`

```
Server Access:
- PRODUCTION_SERVER_IP = 221.164.102.253
- PRODUCTION_SERVER_USER = user
- PRODUCTION_SERVER_SSH_KEY = [SSH private key]

Application:
- JWT_SECRET = [From production .env]
- NEXTAUTH_SECRET = [From production .env]

Infrastructure:
- DB_PASSWORD = [PostgreSQL password]
- GRAFANA_PASSWORD = [Grafana admin password]
```

### Quick Deployment

```bash
# 1. Make changes locally
git add .
git commit -m "feat: your feature"

# 2. Push to GitHub (triggers automated deployment)
git push origin main

# 3. Monitor deployment
# Visit: https://github.com/YOUR_USERNAME/connect/actions

# 4. Verify (after ~4 minutes)
./scripts/verify-deployment.sh
curl https://221.164.102.253/api/health
```

### Verification Scripts (4)

```bash
# Complete system check (pre-deployment)
./scripts/verify-github-actions.sh

# Test SSH connection to production server
./scripts/test-ssh-connection.sh

# Interactive secrets setup helper
./scripts/setup-github-secrets.sh

# Post-deployment verification
./scripts/verify-deployment.sh
```

### Performance Improvements

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Deployment Time** | 35 min | 4 min | **87% faster** |
| **Build Time** | 10 min | 3-4 min | **60% faster** |
| **Image Size** | 1.2 GB | 850 MB | **29% smaller** |
| **Transfer Size** | 1.2 GB | 280 MB | **77% smaller** |
| **Security** | Password | SSH Key | **Enterprise** |
| **Testing** | Manual | Automated | **100% coverage** |

**Monthly Time Saved:** ~10 hours
**Annual Value:** $6,000+ in developer time

### Documentation (Complete)

**Setup & Configuration:**
- `GITHUB-ACTIONS-READY.md` - Current status & quick start
- `QUICK-START-GITHUB-ACTIONS.md` - One-page deployment guide
- `docs/guides/GITHUB-SECRETS-COMPLETE-SETUP.md` - All 7 secrets setup
- `docs/guides/GITHUB-ACTIONS-TESTING.md` - Testing & verification
- `docs/guides/GITHUB-ACTIONS-GUIDE.md` - Complete guide
- `GITHUB-ACTIONS-INDEX.md` - Documentation index

**Session Summaries:**
- `SESSION-53-AUTOMATION-COMPLETE.md` - Initial setup
- `SESSION-53-CONTINUATION-COMPLETE.md` - Secrets & testing completion

### Troubleshooting

**SSH Connection Issues:**
```bash
# Test connection
./scripts/test-ssh-connection.sh

# Manual SSH test
ssh -i ~/.ssh/id_ed25519_connect user@221.164.102.253 "echo 'Connection OK'"
```

**Deployment Failures:**
```bash
# Check GitHub Actions logs in browser
# Run local verification
./scripts/verify-github-actions.sh

# Verify server state
ssh -i ~/.ssh/id_ed25519_connect user@221.164.102.253 "docker ps"
```

**Secret Configuration:**
```bash
# View all required secrets with values
./scripts/setup-github-secrets.sh

# Verify SSH key format (must include BEGIN/END lines)
cat ~/.ssh/id_ed25519_connect | head -1
# Should show: -----BEGIN OPENSSH PRIVATE KEY-----
```

## Architecture Overview

### Single-Server Docker Strategy (with Hot Standby for Peak Season)
- **Primary Hardware**: i9-12900K (16 cores / 24 threads) with 128GB RAM, 1TB NVMe SSD
- **Hot Standby**: Second i9-12900K for Jan-March peak season (99.9% SLO requirement)
- **Deployment**: Docker Compose for operational simplicity
- **Development**: MacBook M4 Max (ARM) ‚Üí Linux server (x86) deployment pipeline
- **Performance Target**: 500-1,500 concurrent users, <500ms P95 response time

### Technology Stack
```
Frontend:    Next.js 14 + TypeScript + Tailwind CSS + shadcn/ui
Backend:     Next.js API Routes (no separate Express server)
Database:    PostgreSQL 15 + PgBouncer (connection pooling)
Cache:       Redis (split: cache instance + queue instance)
Scraping:    NTIS API (axios + xml2js) + Playwright + Bull queue + node-cron
             Hybrid: NTIS API (108K programs, historical patterns) + 
                     Playwright (200-500 active calls, real-time)
Auth:        NextAuth.js + JWT + Kakao/Naver OAuth
Payments:    Toss Payments (subscription + tax invoice)
```

### Docker Service Architecture
```
Cloudflare (DNS + DDoS protection) ‚Üí
Nginx (reverse proxy, SSL, load balancing) ‚Üí
App Container 1 + App Container 2 (Next.js instances) ‚Üí
PgBouncer (transaction pooling) ‚Üí
PostgreSQL 15 + Redis Cache + Redis Queue + Scraper Worker
```

### Resource Allocation (i9-12900K)
```
Total: 16 cores, 128GB RAM

Services:
‚îú‚îÄ‚îÄ Nginx:          1 core,   2GB RAM
‚îú‚îÄ‚îÄ App Instance 1: 3 cores, 10GB RAM
‚îú‚îÄ‚îÄ App Instance 2: 3 cores, 10GB RAM
‚îú‚îÄ‚îÄ PgBouncer:      0.5 core, 1GB RAM
‚îú‚îÄ‚îÄ PostgreSQL:     2 cores, 32GB RAM
‚îú‚îÄ‚îÄ Redis Cache:    1 core,  12GB RAM
‚îú‚îÄ‚îÄ Redis Queue:    1 core,   3GB RAM
‚îú‚îÄ‚îÄ Scraper:        1 core,   4GB RAM
‚îú‚îÄ‚îÄ Monitoring:     0.5 core, 2GB RAM
‚îî‚îÄ‚îÄ Buffer:         4 cores, 52GB RAM (safety margin)

Total allocated: 12 cores (75%) + 4 cores buffer (25%) = 16 cores
```

## Business Model & Revenue Strategy

### Hybrid Model: Software + Services

**Software (SaaS Subscription):**
- **Free**: ‚Ç©0/month - 10 matches/month, basic features (freemium funnel)
- **Pro**: ‚Ç©49,000/month - Unlimited matches, sector gates, outcome data
- **Team**: ‚Ç©99,000/month - 5 seats, consortium tools, priority support
- **Target**: 140 paying users by Month 6 ‚Üí ‚Ç©6.86M MRR

**Services (High-margin Consulting):**
- **Application Review**: ‚Ç©2-3M per project (7-10 days, win rate +10-15%)
- **Certification Planning**: ‚Ç©3-5M (ISMS-P, KC certification roadmap)
- **Consortium Formation**: ‚Ç©3-5M (partner matching, warm intros)
- **TRL Advancement**: ‚Ç©5-7M (technology development consulting)
- **Target**: 10 engagements by Month 6 ‚Üí ‚Ç©30-50M

**Why Hybrid Works:**
1. **Immediate Cash Flow**: Services provide ‚Ç©25M+ from Month 1 (vs. waiting for MRR)
2. **Sustainable Pricing**: ‚Ç©49-99K covers infrastructure without external funding
3. **Defensible Moat**: Competitors can't replicate services expertise
4. **Customer Success**: Services help users win ‚Üí positive outcomes ‚Üí better matching
5. **Profitability**: Break-even Month 1 (vs. Month 8+ with software-only)

**Revenue Projections:**
- Month 3: ‚Ç©18M/month (‚Ç©3.4M MRR + ‚Ç©15M services)
- Month 6: ‚Ç©48M/month (‚Ç©7.9M MRR + ‚Ç©40M services)
- Cumulative Month 1-6: ‚Ç©200M+

### Critical Legal Compliance: Off-Budget Services Invoicing

**MUST KNOW**: Services CANNOT be included in government R&D project budgets.

**Legal Requirement (Íµ≠Í∞ÄÏó∞Íµ¨Í∞úÎ∞úÏÇ¨ÏóÖ Ïó∞Íµ¨Í∞úÎ∞úÎπÑ ÏÇ¨Ïö© Í∏∞Ï§Ä):**
- Connect services = Business development costs (ÏÇ¨ÏóÖÍ∞úÎ∞úÎπÑ)
- Must be invoiced separately from R&D project costs
- Must be paid from company's operating budget (Ïö¥ÏòÅÎπÑ), NOT grant budget (Ïó∞Íµ¨Í∞úÎ∞úÎπÑ)
- Violation = Customer audit risk + Connect legal liability

**MSA Clause (in all service agreements):**
```
Ï†ú4Ï°∞ (ÏÑúÎπÑÏä§ ÎπÑÏö© Ï≤≠Íµ¨)
Î≥∏ ÏÑúÎπÑÏä§Îäî Í∏∞ÏóÖÏùò ÏÇ¨ÏóÖÍ∞úÎ∞ú ÎπÑÏö©ÏúºÎ°ú Ï≤≠Íµ¨ÎêòÎ©∞, 
Ï†ïÎ∂Ä R&D Í≥ºÏ†ú Ïó∞Íµ¨Í∞úÎ∞úÎπÑ ÏòàÏÇ∞Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏäµÎãàÎã§.

Î≤ïÏ†Å Í∑ºÍ±∞:
- „ÄåÍµ≠Í∞ÄÏó∞Íµ¨Í∞úÎ∞úÏÇ¨ÏóÖ Ïó∞Íµ¨Í∞úÎ∞úÎπÑ ÏÇ¨Ïö© Í∏∞Ï§Ä„Äç (IITP Í≥†Ïãú Ï†ú2025-02Ìò∏)
- Ïó∞Íµ¨Í∞úÎ∞úÎπÑÎäî ÏßÅÏ†ëÎπÑ(Ïù∏Í±¥ÎπÑ, Ïó∞Íµ¨Ïû¨Î£åÎπÑ Îì±)ÏôÄ Í∞ÑÏ†ëÎπÑÎ°úÎßå Íµ¨ÏÑ±
- ÏùºÎ∞ò Ïª®ÏÑ§ÌåÖ ÎπÑÏö©ÏùÄ Ïó∞Íµ¨Í∞úÎ∞úÎπÑ Ìï≠Î™© Ïô∏
```

**Sales Process:**
1. Always explain during sales call: "Ïù¥ ÏÑúÎπÑÏä§Îäî Í∑ÄÏÇ¨Ïùò Ïö¥ÏòÅ ÏòàÏÇ∞ÏúºÎ°ú Í≤∞Ï†úÎê©ÎãàÎã§"
2. Invoice separately from any R&D projects
3. FAQ prominently displayed: "Î∂ÄÍ∞Ä ÏÑúÎπÑÏä§ ÎπÑÏö©ÏùÄ R&D ÏòàÏÇ∞Ïóê ÎÑ£ÏùÑ Ïàò ÏûàÎÇòÏöî? ‚Üí ÏïÑÎãàÏöî"

## Data Collection Strategy

### Hybrid Approach: NTIS API + Playwright

**Primary Source: NTIS API** (Phase 1 Complete - Oct 6, 2025)
- **Coverage**: 108,798+ R&D programs (comprehensive government database)
- **Purpose**: Historical pattern analysis, win rate benchmarking, success metrics
- **Schedule**: Daily at 8:00 AM KST
- **Technology**: axios + xml2js for XML parsing
- **Status**: Production-ready, awaiting production key (Oct 14, 2025)
- **Value**: Powers insights like "Í∑ÄÏÇ¨ÏôÄ Ïú†ÏÇ¨Ìïú Ï°∞ÏßÅÏùò ÌèâÍ∑† ÏÑ†Ï†ïÎ•†: 38%"

**Secondary Source: Playwright Web Scraping**
- **Coverage**: 200-500 active calls from 4 agencies (realistic current opportunities)
- **Purpose**: Real-time announcement monitoring
- **Schedule**:
  - Normal: 2x daily (9:00 AM, 3:00 PM KST)
  - Peak Season (Jan-March): 4x daily (9:00 AM, 12:00 PM, 3:00 PM, 6:00 PM KST)
- **Technology**: Playwright + Bull queue + node-cron
- **Rate Limiting**: 10 requests/minute per agency

**Targeted Agencies (4 covering ~55% of R&D budget):**
- **IITP** (Ï†ïÎ≥¥ÌÜµÏã†Í∏∞ÌöçÌèâÍ∞ÄÏõê) - Ministry of Science and ICT (~15% of budget)
- **KEIT** (ÌïúÍµ≠ÏÇ∞ÏóÖÍ∏∞Ïà†ÌèâÍ∞ÄÍ¥ÄÎ¶¨Ïõê) - Ministry of Trade, Industry and Energy (~12% of budget)
- **TIPA** (Ï§ëÏÜåÍ∏∞ÏóÖÍ∏∞Ïà†Ï†ïÎ≥¥ÏßÑÌù•Ïõê) - Ministry of SMEs and Startups (~8% of budget)
- **KIMST** (Ìï¥ÏñëÏàòÏÇ∞Í≥ºÌïôÍ∏∞Ïà†ÏßÑÌù•Ïõê) - Ministry of Oceans and Fisheries

**Deduplication & Integration:**
- Content hashing prevents duplicates from both sources
- `scraping_source` field: 'NTIS_API' or agency id ('iitp', 'keit', etc.)
- Users benefit from: Comprehensive historical data + Real-time updates

**CRITICAL: Honest Claims (No "100K+ programs" overpromising)**
- Homepage: "Íµ≠ÎÇ¥ Ï£ºÏöî 4Í∞ú Í∏∞Í¥Ä ÏµúÏã† Í≥µÍ≥† 200~500Í±¥ (Îß§Ïùº ÏóÖÎç∞Ïù¥Ìä∏)"
- Subtext: "Plus: Ïó≠ÎåÄ R&D Í≥ºÏ†ú 108,000+ Í±¥ ÏÑ±Í≥µ Ìå®ÌÑ¥ Î∂ÑÏÑù"
- Why: Honest expectations ‚Üí higher retention vs. overpromising ‚Üí disappointment ‚Üí churn

## NTIS API Integration Status

**Current Status**: Phase 1 Complete (October 6, 2025) ‚úÖ

### Phase 1: Foundation & Validation (COMPLETE)
**Duration**: ~2 hours | **Completion Date**: October 6, 2025

**Accomplishments**:
- ‚úÖ Dependencies installed (axios ^1.7.2, xml2js ^0.6.2, @types/xml2js ^0.4.14)
- ‚úÖ NTIS API client implemented (`lib/ntis-api/client.ts`)
- ‚úÖ XML parser created (`lib/ntis-api/parser.ts`)
- ‚úÖ Database integration with deduplication (`lib/ntis-api/scraper.ts`)
- ‚úÖ Configuration files (`lib/ntis-api/config.ts`, `lib/ntis-api/types.ts`)
- ‚úÖ Validation script created (`scripts/validate-ntis-integration.ts`)
- ‚úÖ Diagnostic test script (`scripts/test-ntis-simple.ts`)
- ‚úÖ Manual trigger script (`scripts/trigger-ntis-scraping.ts`)
- ‚úÖ Comprehensive documentation (3 files, 1,100+ line roadmap)

**Test Results**:
- API connectivity: ‚úÖ HTTP 200 responses
- Demo key: ‚úÖ Authenticates successfully (returns 0 results as expected for demo key)
- Implementation: ‚úÖ Production-ready
- Database integration: ‚úÖ Working correctly
- Deduplication: ‚úÖ Content hashing functional

**Files Created**:
```
lib/ntis-api/
‚îú‚îÄ‚îÄ client.ts          # API client with retry logic
‚îú‚îÄ‚îÄ parser.ts          # XML response parser
‚îú‚îÄ‚îÄ scraper.ts         # Database integration
‚îú‚îÄ‚îÄ config.ts          # API configuration
‚îú‚îÄ‚îÄ types.ts           # TypeScript interfaces
‚îî‚îÄ‚îÄ index.ts           # Module exports

scripts/
‚îú‚îÄ‚îÄ validate-ntis-integration.ts    # 7 comprehensive checks
‚îú‚îÄ‚îÄ trigger-ntis-scraping.ts        # Manual scraping trigger
‚îî‚îÄ‚îÄ test-ntis-simple.ts             # API parameter diagnostics

Documentation/
‚îú‚îÄ‚îÄ NTIS-PHASE1-COMPLETE.md         # Summary & next steps
‚îú‚îÄ‚îÄ NTIS-PHASE1-TEST-RESULTS.md     # Test results & validation
‚îî‚îÄ‚îÄ NTIS-IMPLEMENTATION-ROADMAP.md  # Phases 2-5 guide (1,100+ lines)
```

### Phases 2-5: Scheduled (October 14, 2025+)
**Trigger**: Production API key arrival (expected Oct 14, 2025)

**Phase 2**: Production API Key Integration (15-20 min)
- Update `.env` with production key
- Run validation script
- Test production scraping
- Verify data quality

**Phase 3**: Hybrid Scheduler Integration (2-3 hours)
- Create NTIS scheduler (`lib/ntis-api/scheduler.ts`)
- Update main scheduler with NTIS integration
- Create hybrid trigger script
- Test combined NTIS + Playwright scraping

**Phase 4**: Monitoring & Optimization (1.5-2 hours)
- Implement logging utility
- Add usage tracker
- Enhanced error handling with retry logic
- Performance monitoring script

**Phase 5**: Production Deployment (1-2 hours)
- Deploy scheduler to production
- Configure monitoring
- Set up alerts
- First 24-hour monitoring

**Complete Roadmap**: See `NTIS-IMPLEMENTATION-ROADMAP.md` for detailed step-by-step instructions.

## Key Features & Implementation

### 1. Enhanced Matching Engine with Sector Gates

**Rule-Based Scoring (0-100 points):**
- Industry match: 30 points
- TRL compatibility: 20 points
- Certifications: 20 points (ISMS-P, KC, ISO 9001)
- Budget fit: 15 points
- R&D experience: 15 points

**Eligibility Gates (Pass/Fail):**
- Organization type (company/institute/both)
- TRL range (strict: ¬±2 levels tolerance)
- Sector-specific requirements:
  - **ISMS-P gate** (SaaS/AI companies): 16-item checklist, readiness score 0-100
  - **KC gate** (Hardware/IoT): 8-item document checklist, testing body selection
- Budget constraints (min/max revenue)

**Match Display:**
- Top 10 matches per user (was 3)
- Score 0-100 with visual indicator
- Estimated win probability (future ML model)
- Korean explanation array
- Status: ‚úÖ Eligible / ‚ö†Ô∏è Warning / üö´ Blocked
- CTA: "Ïã†Ï≤≠ Ï§ÄÎπÑÌïòÍ∏∞" (leads to services)

### 2. Procurement Readiness Calculator

**Purpose**: Help companies qualify for procurement-track funding (ÌòÅÏã†Ï†úÌíà, Ïö∞ÏàòÏ†úÌíà)

**Scoring Model (0-100):**
- Product Maturity (30 points): TRL 9 = 30pts, TRL 8 = 20pts, TRL 7 = 10pts
- Certifications (30 points): KC = 15pts, ISO 9001 = 10pts, ISMS-P = 5pts
- Track Record (20 points): 3+ govt projects = 20pts, 1-2 = 10pts, 0 = 0pts
- Quality System (20 points): Warranty = 7pts, A/S = 7pts, Support = 6pts

**Gap Analysis:**
- Identifies missing requirements
- Estimates time to resolve (1-24 months)
- Estimates cost to resolve (‚Ç©1M-200M)
- Prioritizes gaps (high/medium/low)
- CTAs for services: "TRL ÏÉÅÌñ• Ïª®ÏÑ§ÌåÖ (‚Ç©5-7M)", "Ïù∏Ï¶ù Í≥ÑÌöç (‚Ç©3-5M)"

### 3. Outcome Tracking System (Proprietary Data Moat)

**Purpose**: Create defensible competitive advantage through win rate intelligence

**Data Collection (Opt-in, PIPA-compliant):**
- Application status (applied Y/N, date)
- Result (won/lost/pending/withdrawn)
- Financial data (optional): Requested/award amounts
- Feedback: Difficulty rating (1-5), match quality (1-5)
- Explicit consent checkbox: "Îß§Ïπ≠ Ï†ïÌôïÎèÑ Ìñ•ÏÉÅÏùÑ ÏúÑÌï¥ Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞Î•º Í≥µÏú†Ìï©ÎãàÎã§"

**Privacy-Preserving Aggregation:**
- Minimum 5 data points required for any stat
- Individual results NEVER disclosed
- Example outputs:
  - "Í∑ÄÏÇ¨ÏôÄ Ïú†ÏÇ¨Ìïú ÏÇ∞ÏóÖ(ICT) √ó TRL(7-8) Ï°∞ÏßÅÏùò IITP ÏÑ†Ï†ïÎ•†: 38%"
  - "ÌèâÍ∑† Ïã¨ÏÇ¨ Í∏∞Í∞Ñ: 87Ïùº"
  - "Most successful sectors: ICT (45%), Industrial (32%)"

**Competitive Moat:**
- Competitors only have public announcement data
- Connect has win rates, cycle times, success patterns
- Advantage compounds: More users ‚Üí More data ‚Üí Better predictions
- Roadmap: Basic stats (Y1) ‚Üí ML models (Y2) ‚Üí Prescriptive advice (Y3)

### 4. Services Management System

**Service Types:**
1. Application Review (‚Ç©2-3M, 7-10 days)
2. Certification Planning (‚Ç©3-5M, 2-3 weeks)
3. Consortium Formation (‚Ç©3-5M, 3-4 weeks)
4. TRL Advancement (‚Ç©5-7M, 4-6 weeks)

**Engagement Workflow:**
1. Lead generation (in-app CTAs, email nurture, webinar upsells)
2. Discovery call (30 min, understand need)
3. Proposal (2 days, custom quote + deliverables)
4. Contract signing (MSA with off-budget clause)
5. Kickoff (1 week after payment)
6. Delivery (1-4 weeks depending on service)
7. Follow-up (outcome tracking, testimonial request)

**Conversion Funnel:**
- 1,000 Pro users ‚Üí 100 consult requests ‚Üí 30 proposals ‚Üí 10 closed deals
- Conversion rate: 10% (request ‚Üí close)
- Target: 10 engagements/Month 6 = ‚Ç©30-50M

## Critical Development Considerations

### Hot Standby Requirements (Peak Season: Jan-March)

**Why Critical:**
- January-March = 80% of annual funding announcements
- 27 hours downtime = 50+ users miss deadlines = brand destroyed
- Must have 99.9% SLO during peak season

**Implementation:**
- Second i9-12900K server (hot standby)
- PostgreSQL streaming replication (<5 min RPO)
- Automated failover script (<15 min RTO)
- PagerDuty 24/7 monitoring + SMS alerts
- Weekly health checks during Jan-Mar
- Chaos day testing (Dec 15-20)

**Cost vs. ROI:**
- Cost: ‚Ç©600K/month √ó 3 months = ‚Ç©1.8M
- ROI: Prevents ‚Ç©10-50M revenue loss from churn

### Cross-Platform Build Requirements

**‚ö†Ô∏è CRITICAL - ALWAYS READ THIS BEFORE DOCKER BUILDS:**

**Development Environment:** MacBook Pro M4 Max (ARM64/aarch64 architecture)
**Production Environment:** Linux server 221.164.102.253 (x86_64/amd64 architecture)

**MANDATORY BUILD COMMAND (use in ALL sessions):**
```bash
docker buildx build --platform linux/amd64 -f Dockerfile.production -t connect:latest .
```

**Why This Matters:**
1. **Architecture Mismatch** - ARM builds on Mac will crash on x86 Linux production with missing system libraries
2. **Silent Failures** - Docker won't error during build, but containers fail at runtime with cryptic errors like:
   - `exec /usr/local/bin/node: exec format error` (wrong CPU architecture)
   - `npm ERR! missing: @prisma/client` (native bindings compiled for ARM instead of x86)
   - `libssl.so.3: cannot open shared object file` (wrong system library version)
3. **Production Impact** - Last incident: October 17, 2025 - npm EACCES errors caused 502 downtime

**Alternative: Set Default Platform (optional but recommended)**
Add to your shell profile (`~/.zshrc` or `~/.bashrc`):
```bash
export DOCKER_DEFAULT_PLATFORM=linux/amd64
```
Then restart terminal. All future `docker build` commands will default to x86_64.

**Verification After Build:**
```bash
# Check image architecture (must show "linux/amd64")
docker inspect connect:latest --format='{{.Architecture}}'
```

**Other Requirements:**
- Multi-stage builds for optimized production images (current: ~850MB)
- Use `npm ci --production` in Docker for correct architecture bindings
- Never skip `--platform` flag even if DOCKER_DEFAULT_PLATFORM is set (explicit > implicit)

### Performance Requirements
- API response time: <500ms (P95) for MVP
- Match generation: <3 seconds for top 10 results
- Database query optimization with PgBouncer connection pooling
- Redis split: cache (LRU eviction) + queue (no eviction, AOF persistence)

### Data Freshness
- Normal: Scrape 2x daily (9am, 3pm)
- Peak Season: Scrape 4x daily (9am, 12pm, 3pm, 6pm)
- Change detection via content hashing
- Simple deadline extraction using regex patterns

## Database Schema Highlights

### Core Tables
- `organizations` - Companies + institutes with encrypted ÏÇ¨ÏóÖÏûêÎì±Î°ùÎ≤àÌò∏
- `funding_programs` - 4-agency programs with eligibility criteria
- `funding_matches` - Rule-based matches with explanations
- `users` - Authentication and subscription management
- `subscriptions` - Toss Payments integration

### New Tables (v8.0 Strategic Revision)
- `grant_outcomes` - **Proprietary data moat**: Applied, won/lost, amounts, cycle times
- `services` - Service catalog (4 types)
- `service_engagements` - Project tracking, invoice, satisfaction
- `sector_gate_checklists` - ISMS-P + KC readiness scores
- `procurement_readiness` - Scoring + gap analysis

### Privacy-Preserving Views
```sql
CREATE VIEW aggregate_success_patterns AS
SELECT 
  agency_id, industry_sector, trl_level,
  COUNT(*) as total_applications,
  SUM(CASE WHEN result = 'won' THEN 1 ELSE 0 END) as wins,
  AVG(cycle_days) as avg_cycle_days
FROM grant_outcomes
WHERE allow_aggregate_analytics = TRUE
GROUP BY agency_id, industry_sector, trl_level
HAVING COUNT(*) >= 5; -- Minimum 5 data points
```

## Deployment Workflow

### Primary: Automated GitHub Actions (Recommended)

**Status:** ‚úÖ Production Ready (October 14, 2025)  
**Architecture:** Industry-Standard Entrypoint Pattern (Heroku/AWS/K8s)

```bash
# Automated deployment (87% faster than manual)
git add .
git commit -m "feat: your changes"
git push origin main

# GitHub Actions automatically:
# 1. Builds Docker images (with caching)
# 2. Runs tests + linting + security scans
# 3. SSHs to production server
# 4. Performs zero-downtime rolling update
# 5. Runs health checks (migrations happen inside containers)
# 6. Rolls back on failure
# 7. Sends notifications

# Monitor deployment progress:
# https://github.com/YOUR_USERNAME/connect/actions

# Verify after ~4 minutes:
./scripts/verify-deployment.sh
```

**Architecture Pattern - Entrypoint (Industry Standard):**
- Migrations run **inside containers** on startup (not externally)
- Self-contained: Each container handles its own initialization
- Self-healing: Failed migrations = failed container = automatic rollback
- Health checks validate: Migrations + App + Endpoint (atomic validation)

**Automated Workflow Steps:**
1. **Build** - Docker image with multi-stage caching (3-4 min)
2. **Test** - TypeScript, ESLint, unit tests, security scans
3. **Deploy** - SSH to server, zero-downtime rolling update
4. **Initialize** - Containers run migrations via entrypoint script
5. **Verify** - Health checks on `/api/health` endpoint (post-migration)
6. **Rollback** - Automatic if health checks fail (30 seconds)
7. **Notify** - GitHub PR comments + email on failure

**Performance:**
- Deployment time: **4 minutes** (vs. 35 min manual)
- Build time: **3-4 minutes** (with caching)
- Transfer size: **280 MB** (vs. 1.2 GB full image)
- Zero-downtime: **Always** (blue-green rolling update)
- Code reduction: **75%** (200 lines ‚Üí 50 lines vs. old external migration pattern)

**Key Files:**
- `docker-entrypoint.sh` - Container initialization (migrations ‚Üí app)
- `.github/workflows/deploy-production.yml` - Automated deployment pipeline
- See: [START-HERE-DEPLOYMENT-DOCS.md](./START-HERE-DEPLOYMENT-DOCS.md) for complete documentation

### Deployment Documentation

**üìö Complete deployment architecture documentation:**

**Start Here:**
- [START-HERE-DEPLOYMENT-DOCS.md](./START-HERE-DEPLOYMENT-DOCS.md) - Main navigation
- [DEPLOYMENT-ARCHITECTURE-INDEX.md](./DEPLOYMENT-ARCHITECTURE-INDEX.md) - Complete index
- [DEPLOYMENT-ARCHITECTURE-LESSONS.md](./DEPLOYMENT-ARCHITECTURE-LESSONS.md) - Deep-dive (788 lines)
- [DEPLOYMENT-ARCHITECTURE-QUICK-REFERENCE.md](./DEPLOYMENT-ARCHITECTURE-QUICK-REFERENCE.md) - Quick patterns

**What Changed (Oct 15, 2025):**
- ‚úÖ Replaced external migration orchestration with entrypoint pattern
- ‚úÖ Reduced deployment complexity by 75% (200 ‚Üí 50 lines)
- ‚úÖ Achieved 100% deployment success (was 5 failed attempts)
- ‚úÖ Industry-standard architecture (Heroku/AWS/Kubernetes model)

**Deprecated (Don't Use):**
- ‚ùå `scripts/deploy.sh` - Old manual deployment with external migrations
- ‚ùå `docs/architecture/DEPLOYMENT-STRATEGY.md` - Describes old pattern
- ‚ùå External migration coordination (docker run for migrations)

See [DEPLOYMENT-DOCS-STATUS.md](./DEPLOYMENT-DOCS-STATUS.md) for complete documentation status

### Directory Structure
```bash
/opt/connect/
‚îú‚îÄ‚îÄ docker-compose.production.yml
‚îú‚îÄ‚îÄ .env.production
‚îú‚îÄ‚îÄ config/           # Nginx, PostgreSQL, Grafana configs
‚îú‚îÄ‚îÄ scripts/          # Deployment and operational scripts
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh           # Zero-downtime deployment
‚îÇ   ‚îú‚îÄ‚îÄ rollback.sh         # Emergency rollback
‚îÇ   ‚îú‚îÄ‚îÄ backup.sh           # Automated backups
‚îÇ   ‚îú‚îÄ‚îÄ failover.sh         # Hot standby failover (Jan-Mar)
‚îÇ   ‚îî‚îÄ‚îÄ health-monitor.sh   # System health monitoring
‚îú‚îÄ‚îÄ logs/             # Application and service logs
‚îú‚îÄ‚îÄ backups/          # Automated backups (PostgreSQL, Redis, uploads)
‚îú‚îÄ‚îÄ data/             # Persistent data (Grafana, scraper state)
‚îî‚îÄ‚îÄ uploads/          # User-uploaded files
```

### Health Checks Required
1. API endpoint availability (`/api/health`)
2. Database connectivity via PgBouncer
3. Redis cache and queue connectivity
4. Docker container health status
5. Scraping job success rates (NTIS API + Playwright)
6. Nginx reverse proxy status
7. Hot standby replication lag (during Jan-March)

## Key Documentation Files

### Strategic Documents
- `docs/current/PRD_v8.0.md`: **START HERE** - Complete product requirements with strategic pivot (companies-first, hybrid model, services, outcome tracking)
- `CONNECT_FINAL_PROPOSAL_v1.0.md` (Desktop): Executive summary of multi-AI debate synthesis
- `CONNECT_IMPLEMENTATION_SPECS_v1.0.md` (Desktop): Parts 1-4 (Database schema, MSA, UI copy, Email templates)
- `CONNECT_IMPLEMENTATION_SPECS_v1.0_PART2.md` (Desktop): Parts 5-8 (API specs, Code snippets, Config, Deployment)

### Architecture & Deployment
- `docs/current/Deployment_Architecture_v3.md`: Docker-based production deployment guide
- `docs/current/NTIS_Agency_Scraping_Config_v2.md`: 4-agency scraping implementation
- `docs/guides/LOAD_TESTING.md`: k6 load testing guide and performance targets
- `docker-compose.production.yml`: Production Docker stack configuration
- `.env.production.example`: Environment variables template

### NTIS API Integration
- **`NTIS-PHASE1-COMPLETE.md`** - Executive summary (Phase 1 done, awaiting Oct 14 key)
- **`NTIS-PHASE1-TEST-RESULTS.md`** - Complete test results (15 KB, 5/7 PASS)
- **`NTIS-IMPLEMENTATION-ROADMAP.md`** - Phases 2-5 guide (33 KB, 1,100+ lines)
- `scripts/validate-ntis-integration.ts` - 7 comprehensive health checks
- `scripts/trigger-ntis-scraping.ts` - Manual NTIS trigger
- `scripts/test-ntis-simple.ts` - API diagnostics

### GitHub Actions CI/CD (Complete - October 14, 2025)

**Setup & Configuration:**
- **`GITHUB-ACTIONS-READY.md`** - **START HERE** - Current status & quick deployment guide
- **`QUICK-START-GITHUB-ACTIONS.md`** - One-page reference (setup in 5 minutes)
- **`docs/guides/GITHUB-SECRETS-COMPLETE-SETUP.md`** - All 7 secrets with exact values
- **`docs/guides/GITHUB-ACTIONS-TESTING.md`** - Complete testing & verification guide
- **`docs/guides/GITHUB-ACTIONS-GUIDE.md`** - Comprehensive GitHub Actions guide
- **`GITHUB-ACTIONS-INDEX.md`** - Complete documentation index

**Verification Scripts:**
- `scripts/verify-github-actions.sh` - Complete system verification (pre-deployment)
- `scripts/test-ssh-connection.sh` - SSH connection testing (‚úÖ PASSING)
- `scripts/setup-github-secrets.sh` - Interactive secrets setup helper
- `scripts/verify-deployment.sh` - Post-deployment verification & health checks

**Workflow Files:**
- `.github/workflows/ci.yml` - CI testing on every PR (tests, lint, security)
- `.github/workflows/deploy-production.yml` - Production deployment (SSH key auth)
- `.github/workflows/preview-deploy.yml` - PR preview environments

**Session Summaries:**
- `SESSION-53-AUTOMATION-COMPLETE.md` - Initial CI/CD setup (workflows, optimization)
- `SESSION-53-CONTINUATION-COMPLETE.md` - Secrets collection & testing completion

**Key Achievement:** 87% faster deployments (35 min ‚Üí 4 min), SSH key authentication

### Implementation Documentation

**Phase-by-phase retrospectives** documenting foundational decisions. **Read these first** when starting new work.

- **[Phase 1A: Infrastructure Foundation](docs/implementation/phase1a-infrastructure.md)** (8-12 hours)
  - Tech stack (Next.js 14, PostgreSQL 15, Prisma ORM, Redis, Docker Compose)
  - OAuth (Kakao, Naver with NextAuth.js)
  - Security (AES-256-GCM encryption, SHA-256 hashing, rate limiting)
  - Database schema (8 models, 14 enums, 25+ indexes, PIPA compliant)
  - **Key Decisions**: PostgreSQL vs MongoDB, Prisma vs TypeORM, Docker Compose vs K8s

- **[Phase 2A: Match Generation System](docs/implementation/phase2a-match-generation.md)** (3-4 hours)
  - Core matching algorithm (Industry 30pts, TRL 20pts, Type 20pts, R&D 15pts, Deadline 15pts)
  - Korean explanation generator
  - Match generation API with subscription-based rate limiting
  - Match viewing UI with cards, score visualization, CTAs
  - Database seeding (16 programs from 4 agencies)
  - **Key Features**: Explainable AI, Content hashing, Redis rate limiting

### Status & Testing Reports
- `docs/status/deployment-ready.md`: Production deployment readiness checklist
- `docs/status/implementation-status.md`: Feature implementation progress
- `docs/status/oauth-ready-report.md`: OAuth integration test results
- `docs/status/oauth-test-guide.md`: How to test Kakao/Naver OAuth
- `docs/status/testing-summary.md`: Unit and E2E test coverage

**When to reference these docs:**
- **Onboarding:** Read Phase 1A ‚Üí Phase 2A (5-6 hours) to understand platform
- **Design decisions:** Reference "Key Decisions" sections
- **Debugging:** Understand original design intent
- **New features:** Follow established patterns
- **Refactoring:** Know trade-offs before changing architecture

## Environment Variables Reference

All environment variables documented in `.env.production.example`. Key categories:

### Critical (MUST be configured):
- `ENCRYPTION_KEY` - AES-256-GCM key for ÏÇ¨ÏóÖÏûêÎì±Î°ùÎ≤àÌò∏ (PIPA compliance)
- `DATABASE_URL` - PostgreSQL connection (via PgBouncer)
- `REDIS_CACHE_URL` / `REDIS_QUEUE_URL` - Cache and job queue instances
- `JWT_SECRET` / `NEXTAUTH_SECRET` - Auth secrets (rotate every 90 days)

### OAuth & Payments:
- `KAKAO_CLIENT_ID` / `KAKAO_CLIENT_SECRET` - Kakao OAuth
- `NAVER_CLIENT_ID` / `NAVER_CLIENT_SECRET` - Naver OAuth
- `TOSS_CLIENT_KEY` / `TOSS_SECRET_KEY` - Toss Payments (subscription + tax invoice)

### Scraping:
- `NTIS_API_KEY` - NTIS API authentication (production key arriving Oct 14, 2025)
  - Demo key: `yx6c98kg21bu649u2m8u` (authenticates, 0 results)
  - Production key: Access to 108,798+ programs
  - Get from: https://www.ntis.go.kr/rndopen/api/mng/apiMain.do
  - Support: 042-869-1115, ntis@kisti.re.kr
- `TWOCAPTCHA_API_KEY` - Optional CAPTCHA solving ($1-5/month)
- `SCRAPING_SCHEDULE_NORMAL` / `SCRAPING_SCHEDULE_PEAK` - Cron expressions
- `RATE_LIMIT_PER_MINUTE` - Agency scraping rate limit (default: 10)

## Business Context (Revised Strategic Positioning)

### Target Market (Revised GTM)

**Primary: Companies (90% of revenue)**
- **Size**: 10,000+ SMEs seeking government R&D funding
- **Pain**: Don't know grants exist, miss deadlines, low win rates (15-20%)
- **Budget Authority**: Can pay ‚Ç©49-99K/month software + ‚Ç©2-7M services
- **Peak Season**: January-March (80% of announcements)
- **Why Primary**: Companies need discovery + execution support, have budget authority

**Secondary: Research Institutes (10% of revenue)**
- **Size**: 200+ institutes (95% founder network)
- **Role**: Supply-side for consortium matching (not primary customers)
- **Value**: Free platform access for partnership opportunities
- **Why Secondary**: Institutes have multi-year budgets, don't need grant "discovery"

**Critical GTM Lesson:**
- Original assumption: Research institutes = primary customers (95% network = advantage)
- Reality: Institutes don't pay for discovery (they already know their grants)
- **Pivot**: Companies = primary paying customers. Use professor network for **company introductions**, not institute signups.

### User Personas

**Company Users (Primary):**
- R&D Directors, CEOs (small companies), Business Development Managers
- Pain points: Discovery problem, deadline anxiety, low win rates (15-20%), application quality
- Jobs to be done: Discover grants, qualify eligibility, apply with quality, win funding, track outcomes
- Budget: ‚Ç©49-99K/month software + ‚Ç©2-7M services (can approve both)

**Research Institute Users (Secondary):**
- Government-funded (KIST, ETRI) or private research centers
- Pain points: Finding industry partners, tech transfer barriers, TRL matching
- Value proposition: Free platform access for consortium opportunities
- Role: Supply-side (companies need institutes as consortium partners)

### Competitive Positioning
- vs. Manual search: Automated 4-agency monitoring + explainable matching
- vs. ChatGPT (‚Ç©25,000/month): Specialized Korean R&D data + outcome intelligence
- vs. Consultants: Hybrid software + services (consultants can't scale, SaaS can't deliver expertise)
- **Unique moats**: Outcome data, services layer, network effects, compliance (off-budget)

### Pricing Strategy
- **Beta (First 50)**: ‚Ç©4,900/month for 30 days ‚Üí Auto-upgrade to ‚Ç©49,000
- **Free**: ‚Ç©0/month, 10 matches/month (freemium funnel)
- **Pro**: ‚Ç©49,000/month (sustainable pricing, covers infrastructure)
- **Team**: ‚Ç©99,000/month (5 seats, for larger teams)
- **Services**: ‚Ç©2-7M per engagement (off-budget invoicing, company operating budget only)

### Success Metrics (Revised)
- **Launch**: 50 beta users (45 companies, 5 institutes) by Week 9
- **Public**: 500 users by Month 4
- **Engagement**: 70%+ weekly active, >4.0 match quality rating
- **Retention**: 70%+ after 3 months (gate for 1,000 user expansion)
- **Conversion**: 25%+ Free ‚Üí Pro within 30 days
- **Revenue**: ‚Ç©10M+/month by Month 4 (software + services), ‚Ç©200M cumulative by Month 6
- **Outcome tracking**: >60% opt-in rate for sharing application results

## Critical Constraints & Requirements

1. **Companies-first GTM** - Primary paying customers, not research institutes
2. **Hybrid revenue model** - Software + services, profitable Month 1
3. **Off-budget services invoicing** - Legal compliance, customer protection
4. **Honest claims** - 200-500 active programs + 108K historical patterns (not "100K+ programs")
5. **Hot standby for peak season** - 99.9% SLO during Jan-March
6. **Outcome data collection** - PIPA-compliant, opt-in, aggregate-only
7. **Sector gates** - ISMS-P, KC prevent ineligible applications
8. **Single-server optimization** - Leverage 128GB RAM, 16 cores efficiently
9. **Respect agency websites** - Follow robots.txt, rate limiting (10 req/min)
10. **Docker for production** - Operational simplicity and reliability

---

**Summary**: Connect is not a grant discovery tool. Connect is Korea's R&D commercialization operating system, combining software automation with professional services to help companies discover, apply for, and win government funding. The hybrid business model (software + services) ensures profitability from Month 1 while building defensible competitive advantages through proprietary outcome data.
