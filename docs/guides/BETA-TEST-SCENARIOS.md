# Connect Beta Test Scenarios

**Version**: 1.0
**Last Updated**: October 10, 2025
**Target Audience**: Beta testers, QA team, internal testing
**Test Period**: Week 8-10 (November 27 - December 17, 2025)

---

## Overview

This document provides detailed test scenarios for Connect's beta testing phase. Each scenario includes step-by-step instructions, expected results, and feedback points to capture.

**Testing Goals:**
1. Validate rule-based matching accuracy (0-100 scoring)
2. Test AI features (Claude Sonnet 4.5 explanations and Q&A chat)
3. Verify circuit breaker and fallback system (99.9% availability)
4. Stress test performance (<500ms P95 response time)
5. Identify UX issues, bugs, and improvement opportunities

**Testing Methodology:**
- **Exploratory testing**: Free-form usage to discover edge cases
- **Structured scenarios**: Step-by-step test cases (documented below)
- **Performance testing**: Measure response times, cache hit rates
- **Accessibility testing**: Keyboard navigation, screen readers
- **Cross-device testing**: Desktop, mobile, tablet

---

## Table of Contents

1. [Scenario 1: Account Creation & Organization Setup](#scenario-1-account-creation--organization-setup)
2. [Scenario 2: Match Generation & Scoring Validation](#scenario-2-match-generation--scoring-validation)
3. [Scenario 3: AI Match Explanation Quality](#scenario-3-ai-match-explanation-quality)
4. [Scenario 4: Q&A Chatbot Conversation Flow](#scenario-4-qa-chatbot-conversation-flow)
5. [Scenario 5: Fallback System & Circuit Breaker](#scenario-5-fallback-system--circuit-breaker)
6. [Scenario 6: Sector Gates (ISMS-P, KC)](#scenario-6-sector-gates-isms-p-kc)
7. [Scenario 7: Feedback Widget Submission](#scenario-7-feedback-widget-submission)
8. [Scenario 8: Performance & Responsiveness](#scenario-8-performance--responsiveness)
9. [Scenario 9: Mobile Experience](#scenario-9-mobile-experience)
10. [Scenario 10: Edge Cases & Error Handling](#scenario-10-edge-cases--error-handling)

---

## Scenario 1: Account Creation & Organization Setup

### Objective
Test user onboarding flow from account creation to first match generation.

### Prerequisites
- None (fresh start)

### Steps

**1.1 Create Account via Kakao OAuth**
1. Navigate to: https://connect.kr
2. Click "ì‹œì‘í•˜ê¸°" (Get Started) button
3. Click "ì¹´ì¹´ì˜¤ë¡œ ì‹œì‘í•˜ê¸°" (Continue with Kakao)
4. Authorize Kakao OAuth (use real or test account)
5. Verify redirect to dashboard

**Expected Results:**
- OAuth authorization screen loads within 2 seconds
- Redirect to dashboard after authorization
- Welcome message displayed: "í™˜ì˜í•©ë‹ˆë‹¤, {name}ë‹˜!"

**Feedback to Capture:**
- Was OAuth process smooth?
- Any confusing steps?
- Response time acceptable?

---

**1.2 Complete Organization Profile (Company)**
1. Navigate to: Dashboard â†’ Settings â†’ Organization Info
2. Fill required fields:
   - Organization name: "ABCí…Œí¬ë†€ë¡œì§€"
   - Organization type: "ê¸°ì—…" (Company)
   - Business number: 123-45-67890
   - Industry: "ICT"
   - TRL level: 7
3. Fill optional fields:
   - Annual revenue: "â‚©1B - â‚©10B" (â‚©1ì–µ~10ì–µ)
   - R&D experience: "3-5 projects"
   - Certifications: Check "ISMS-P"
4. Click "ì €ì¥" (Save)

**Expected Results:**
- All fields save successfully
- Business number encrypted (display as ***-**-***90)
- Success message: "ì¡°ì§ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤"
- Profile completeness: 100%

**Feedback to Capture:**
- Are field labels clear?
- Is business number encryption visible?
- Any missing fields?

---

**1.3 Alternative: Research Institute Profile**
1. Organization type: "ì—°êµ¬ì†Œ" (Research Institute)
2. Fill required fields:
   - Institute type: "Government-funded"
   - Research focus areas: ["ì¸ê³µì§€ëŠ¥", "ë¹…ë°ì´í„°"]
   - Researcher count: 50
3. Optional: Annual R&D budget, key technologies

**Expected Results:**
- Different field set displayed for institutes vs. companies
- Validation errors if required fields missing

---

## Scenario 2: Match Generation & Scoring Validation

### Objective
Validate rule-based matching algorithm accuracy and scoring.

### Prerequisites
- Completed organization profile setup (Scenario 1)

### Steps

**2.1 Generate First Matches**
1. Navigate to: Dashboard
2. Click "ë§¤ì¹­ ì‹œì‘" (Start Matching) button
3. Wait for algorithm to run (2-3 seconds)
4. View top 10 matches

**Expected Results:**
- Matches generated within 3 seconds
- Top 10 matches displayed, sorted by score (highest first)
- Each match shows:
  - Match score (0-100)
  - Program title (Korean)
  - Agency badge (IITP, KEIT, TIPA, KIMST)
  - Deadline countdown
  - Eligibility status (âœ… Eligible / âš ï¸ Warning / ğŸš« Blocked)

**Feedback to Capture:**
- Are top matches relevant to your organization?
- Is the 0-100 score intuitive?
- Any obviously wrong matches in top 10?

---

**2.2 Validate Score Breakdown**
1. Click on top match to view details
2. Navigate to "Match Score Breakdown" section
3. Verify score components:
   - Industry match: 0-30 points
   - TRL compatibility: 0-20 points
   - Certifications: 0-20 points
   - Budget fit: 0-15 points
   - R&D experience: 0-15 points

**Expected Results:**
- Score breakdown sums to total match score
- Components explained in Korean
- Visual indicator (progress bars or color-coded)

**Test Cases:**

| Organization Profile | Expected Top Match Characteristics |
|----------------------|-----------------------------------|
| ICT, TRL 7, ISMS-P | ICT/software programs, TRL 5-9, ISMS-P required |
| Industrial, TRL 9, ISO 9001 | Industrial programs, TRL 7-9, manufacturing focus |
| Bio/Healthcare, TRL 5, no certs | Bio programs, TRL 3-7, entry-level requirements |

**Feedback to Capture:**
- Do score components make sense?
- Are weightings appropriate? (e.g., Industry 30pts feels right?)
- Any missing factors?

---

**2.3 Test Eligibility Gates**
1. View match details for programs with eligibility gates
2. Check "Eligibility Gates" section
3. Verify pass/fail status:
   - Organization type: âœ… Pass / ğŸš« Fail
   - TRL range: âœ… Within Â±2 levels / ğŸš« Outside range
   - Sector gates: ISMS-P, KC (if applicable)
   - Budget constraints: âœ… Within min/max / ğŸš« Outside

**Expected Results:**
- Clear pass/fail indicators
- Explanation of why blocked (if blocked)
- CTA: "ìê²© ìš”ê±´ ì¶©ì¡±í•˜ê¸°" (Meet Requirements) â†’ Links to services

**Feedback to Capture:**
- Are eligibility gates clear?
- Do you understand why blocked?
- Are recommendations helpful?

---

## Scenario 3: AI Match Explanation Quality

### Objective
Test Claude Sonnet 4.5 match explanation generation and caching.

### Prerequisites
- Generated matches (Scenario 2)

### Steps

**3.1 Generate First AI Explanation (Uncached)**
1. Click "AI ì„¤ëª… ë³´ê¸°" (View AI Explanation) on top match
2. Measure response time (should be 2-5 seconds)
3. Read explanation (400-500 characters)
4. Verify content:
   - âœ… Strengths section (why match is good)
   - âš ï¸ Cautions section (potential issues)
   - ğŸ’¡ Recommendations section (next steps)

**Expected Results:**
- Response time: 2-5 seconds (P95 <5s)
- Natural Korean language
- Personalized to your organization
- Actionable recommendations

**Example Expected Output:**
```
ê·€ì‚¬(ABCí…Œí¬ë†€ë¡œì§€, ICT, TRL 7)ëŠ” ì´ ê³¼ì œì— ì í•©í•©ë‹ˆë‹¤(ë§¤ì¹­ ì ìˆ˜: 82ì ).

âœ… ê°•ì :
- ì‚°ì—… ë¶„ì•¼ ì™„ë²½ ì¼ì¹˜ (ICT, 30ì )
- TRL í˜¸í™˜ì„± ìš°ìˆ˜ (TRL 7-8 ìš”êµ¬, ê·€ì‚¬ TRL 7, 20ì )
- ISMS-P ì¸ì¦ ë³´ìœ  (20ì )

âš ï¸ ì£¼ì˜ì‚¬í•­:
- ì˜ˆì‚° ë²”ìœ„ ìƒí•œ ê·¼ì ‘ (ì—°ë§¤ì¶œ â‚©500M, ê³¼ì œ ìµœëŒ€ â‚©600M ìš”êµ¬)

ğŸ’¡ ì¶”ì²œ ì‚¬í•­:
ì»¨ì†Œì‹œì—„ êµ¬ì„±ì„ ê³ ë ¤í•˜ì„¸ìš”. í‰ê·  +15% ì„ ì •ë¥  í–¥ìƒ.
```

**Feedback to Capture:**
- Is the Korean natural and professional?
- Does the explanation help you understand WHY this program matches?
- Are recommendations actionable?
- Is 400-500 characters the right length? (too short / too long / just right)

---

**3.2 Test Caching (Second Request)**
1. Click "AI ì„¤ëª… ë³´ê¸°" again on SAME match
2. Measure response time (should be <200ms)
3. Verify explanation is identical to first request

**Expected Results:**
- Response time: <200ms (instant, from Redis cache)
- Identical content to first request
- No visible "loading" state

**Feedback to Capture:**
- Did you notice the speed difference?
- Is caching transparent (you don't notice it)?

---

**3.3 Test Multiple Explanations (Uniqueness)**
1. Generate explanations for top 3 matches
2. Compare explanations side-by-side
3. Verify each explanation is unique and relevant

**Expected Results:**
- Each explanation addresses different match characteristics
- No generic/templated responses
- Personalized to each program

**Feedback to Capture:**
- Are explanations unique or feel copy-pasted?
- Do explanations address different programs' unique requirements?

---

## Scenario 4: Q&A Chatbot Conversation Flow

### Objective
Test Claude Sonnet 4.5 Q&A chatbot with context-aware responses.

### Prerequisites
- Generated matches (Scenario 2)

### Steps

**4.1 Start Conversation (Eligibility Question)**
1. Click "AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°" (Ask AI) on a match card
2. Chatbot opens in sidebar with program context pre-loaded
3. Type question: "ìš°ë¦¬ íšŒì‚¬ê°€ ì´ ê³¼ì œì— ì§€ì›í•  ìˆ˜ ìˆë‚˜ìš”?"
4. Wait for AI response (2-5 seconds)

**Expected Results:**
- Response time: 2-5 seconds
- AI checks:
  - Organization type match (company vs. institute)
  - TRL compatibility
  - Industry sector match
  - Certification requirements
- Response format:
  - âœ… Eligible / âš ï¸ Warning / ğŸš« Ineligible
  - Explanation of each requirement
  - Recommendations if not fully eligible

**Example Expected Response:**
```
ë„¤, ê·€ì‚¬(ABCí…Œí¬ë†€ë¡œì§€)ëŠ” ì´ ê³¼ì œì˜ ê¸°ë³¸ ìê²© ìš”ê±´ì„ ì¶©ì¡±í•©ë‹ˆë‹¤:

âœ… ì¡°ì§ ìœ í˜•: ì¤‘ì†Œê¸°ì—… (ìš”êµ¬ì‚¬í•­: ê¸°ì—…)
âœ… TRL ìˆ˜ì¤€: 7 (ìš”êµ¬ì‚¬í•­: TRL 7-9)
âœ… ì‚°ì—… ë¶„ì•¼: ICT (ìš”êµ¬ì‚¬í•­: ICT/ì†Œí”„íŠ¸ì›¨ì–´)
âœ… ISMS-P ì¸ì¦ ë³´ìœ  (ê°€ì  ìš”ì†Œ)

ë‹¤ë§Œ, ê³¼ê±° R&D ìˆ˜í–‰ ì‹¤ì ì´ 1-2ê±´ìœ¼ë¡œ í‰ê· (3-5ê±´)ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤.
ì»¨ì†Œì‹œì—„ êµ¬ì„±ì„ í†µí•´ ì‹¤ì ì„ ë³´ì™„í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
```

**Feedback to Capture:**
- Is the answer accurate based on your profile?
- Is the format clear (âœ…/âš ï¸/ğŸš«)?
- Are recommendations helpful?

---

**4.2 Follow-up Question (TRL Compatibility)**
1. Type: "TRL 7ì¸ë° TRL 8-9 ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•  ìˆ˜ ìˆë‚˜ìš”?"
2. Verify AI remembers previous conversation context

**Expected Results:**
- AI acknowledges your organization's TRL 7 (from previous message)
- Explains TRL advancement strategies:
  - Pilot testing (TRL 7 â†’ TRL 8)
  - Commercial production planning (TRL 8 â†’ TRL 9)
  - Timeline estimates (6-12 months)
  - Cost estimates (â‚©50-200M)
- CTA: "TRL ìƒí–¥ ì»¨ì„¤íŒ… (â‚©5-7M)"

**Feedback to Capture:**
- Did AI remember context from previous message?
- Is TRL advancement advice practical?

---

**4.3 Consortium Question**
1. Type: "ì»¨ì†Œì‹œì—„ì„ ì–´ë–»ê²Œ êµ¬ì„±í•˜ë‚˜ìš”?"
2. Verify AI provides actionable steps

**Expected Results:**
- AI explains consortium formation process
- Recommends:
  - Partner types (research institutes, universities)
  - Role division (company: commercialization, institute: R&D)
  - Budget allocation (typical 60/40 split)
- CTAs:
  - "ì»¨ì†Œì‹œì—„ ë§¤ì¹­ ì„œë¹„ìŠ¤ (â‚©3-5M)"
  - Free "íŒŒíŠ¸ë„ˆ ì°¾ê¸°" feature

**Feedback to Capture:**
- Is consortium advice clear?
- Are CTAs non-intrusive?

---

**4.4 Test Conversation Memory (5+ messages)**
1. Continue conversation for 5+ message exchanges
2. Ask question referencing earlier messages
3. Example: "ì•ì„œ ë§ì”€í•˜ì‹  ì»¨ì†Œì‹œì—„ ë¹„ìš©ì´ ì–¼ë§ˆì˜€ë‚˜ìš”?"

**Expected Results:**
- AI remembers last 10 messages (sliding window)
- Can reference previous topics
- Conversation feels coherent

**Feedback to Capture:**
- Does conversation feel natural?
- Does AI "forget" important context?
- Is 10-message memory sufficient?

---

**4.5 Test Edge Cases**

| Test Case | Input | Expected Behavior |
|-----------|-------|-------------------|
| Very long question (>500 chars) | Paste 3 paragraphs | AI summarizes and answers concisely |
| Typos and informal Korean | "ì´ ê³¼ì œ ì§€ì›í• ìˆ˜ì‡ë‚˜ì—¬?" | AI understands and responds professionally |
| English question | "Can we apply for this?" | AI responds in English |
| Ambiguous question | "ì´ê±° ì¢‹ë‚˜ìš”?" | AI asks for clarification |
| Off-topic question | "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œìš”?" | AI redirects to funding topics |

**Feedback to Capture:**
- How does AI handle errors gracefully?
- Are ambiguous responses frustrating?

---

## Scenario 5: Fallback System & Circuit Breaker

### Objective
Verify service availability when AI API is down (99.9% SLO).

### Prerequisites
- Contact admin to manually trigger circuit breaker

### Steps

**5.1 Circuit Breaker CLOSED (Normal Operation)**
1. Verify current circuit state in Redis:
   ```bash
   redis-cli GET ai:circuit-breaker:status
   # Expected: "CLOSED" or null (default CLOSED)
   ```
2. Generate AI explanation (should work normally)
3. Chat with AI (should work normally)

**Expected Results:**
- AI features work as expected
- Response times: 2-5 seconds

---

**5.2 Admin Triggers Circuit OPEN**
1. Admin runs:
   ```bash
   redis-cli SET ai:circuit-breaker:status "OPEN"
   redis-cli EXPIRE ai:circuit-breaker:status 300
   ```
2. Try to generate AI explanation
3. Try Q&A chat

**Expected Results:**
- Circuit breaker detects OPEN state
- Requests fail fast (<100ms, no waiting)
- Fallback content displayed:
  - **Match explanation**: Generic Korean explanation with CTAs
  - **Q&A chat**: Context-aware template response

**Example Fallback (Match Explanation):**
```
ì´ ê³¼ì œëŠ” ê·€ì‚¬ì˜ í”„ë¡œí•„ê³¼ ì¼ì¹˜í•˜ëŠ” ì ì´ ë§ìŠµë‹ˆë‹¤.

âœ… ì‚°ì—… ë¶„ì•¼: ICT (ê·€ì‚¬ì™€ ì¼ì¹˜)
âœ… TRL ìˆ˜ì¤€: 7-9 (ê·€ì‚¬ TRL 7 í¬í•¨)
âœ… ì¡°ì§ ìœ í˜•: ê¸°ì—… (ê·€ì‚¬ì™€ ì¼ì¹˜)

AI ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì¼ë°˜ ì•ˆë‚´ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

ğŸ’¡ ì§€ì› ì „ í™•ì¸ ì‚¬í•­:
1. ìê²© ìš”ê±´ (ì¡°ì§ ìœ í˜•, TRL, ì¸ì¦)
2. ì˜ˆì‚° ë²”ìœ„ (ìµœì†Œ/ìµœëŒ€ ë§¤ì¶œ ìš”êµ¬ì‚¬í•­)
3. ì‹ ì²­ ë§ˆê°ì¼ (ì¶©ë¶„í•œ ì¤€ë¹„ ì‹œê°„ í™•ë³´)

ğŸ“ ìì„¸í•œ ìƒë‹´: support@connect.kr
```

**Feedback to Capture:**
- Did you notice the circuit breaker was OPEN?
- Was fallback content still useful? (1-5 scale)
- How long would you tolerate fallback mode before contacting support? (5 min / 30 min / 24 hours)
- Were you frustrated by degraded service?

---

**5.3 Circuit HALF_OPEN (Testing Recovery)**
1. Wait 30 seconds (circuit auto-transitions to HALF_OPEN)
2. Try to generate AI explanation (1 request allowed)
3. Verify:
   - If AI succeeds â†’ Circuit goes CLOSED
   - If AI fails â†’ Circuit stays OPEN for another 30s

**Expected Results:**
- Automatic recovery testing
- User not aware of HALF_OPEN state (seamless)

---

**5.4 Circuit CLOSED (Recovery Complete)**
1. Admin clears circuit state:
   ```bash
   redis-cli DEL ai:circuit-breaker:status
   ```
2. Generate AI explanation
3. Verify normal operation resumed

**Expected Results:**
- AI features work normally again
- Response times back to 2-5 seconds

**Feedback to Capture:**
- Was recovery seamless?
- Did you notice when service returned to normal?

---

## Scenario 6: Sector Gates (ISMS-P, KC)

### Objective
Test sector-specific eligibility gates for SaaS/AI companies (ISMS-P) and hardware/IoT (KC).

### Prerequisites
- Organization profile with ISMS-P or KC certification requirement

### Steps

**6.1 ISMS-P Gate (SaaS/AI Companies)**
1. Navigate to match details for program requiring ISMS-P
2. View "Sector Gates" section
3. If ISMS-P not held:
   - See readiness score: 0-100
   - See 16-item checklist:
     - Risk assessment
     - Security policy
     - Access control
     - Encryption
     - Incident response
     - PIPA compliance
     - ...
   - Estimate time to obtain: 6-12 months
   - Estimate cost: â‚©20-50M
4. CTA: "ISMS-P ì¸ì¦ ê³„íš (â‚©3-5M)"

**Expected Results:**
- Clear blocked status (ğŸš«)
- Actionable checklist (not just "you need ISMS-P")
- Realistic timeline and cost estimates
- Non-intrusive CTA

**Feedback to Capture:**
- Is the checklist helpful?
- Are estimates realistic?
- Does this help you decide whether to pursue?

---

**6.2 KC Gate (Hardware/IoT Companies)**
1. Navigate to match for program requiring KC certification
2. View "Sector Gates" section
3. If KC not held:
   - See 8-item document checklist:
     - Product spec sheet
     - Test report (safety, EMC)
     - Manufacturing process
     - Quality management system
     - User manual
     - ...
   - Testing body selection (KTC, KTL, KTR)
   - Estimate time: 3-6 months
   - Estimate cost: â‚©5-30M (varies by product)
4. CTA: "KC ì¸ì¦ ê³„íš (â‚©3-5M)"

**Expected Results:**
- Document checklist practical
- Testing body recommendations based on product type
- Realistic timeline/cost

**Feedback to Capture:**
- Is KC gate information accurate?
- Would this help you prepare?

---

## Scenario 7: Feedback Widget Submission

### Objective
Test in-app feedback collection system.

### Prerequisites
- None

### Steps

**7.1 Submit Bug Report**
1. Click floating "ğŸ’¬ í”¼ë“œë°±" button (bottom-right)
2. Select category: "ğŸ› ë²„ê·¸ ë¦¬í¬íŠ¸"
3. Title: "ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜"
4. Description:
   ```
   ë§¤ì¹­ ì ìˆ˜ê°€ ìŒìˆ˜(-5ì )ë¡œ í‘œì‹œë©ë‹ˆë‹¤.

   ë°œìƒ ìƒí™©:
   - ì¡°ì§ í”„ë¡œí•„: ICT, TRL 5
   - ê³¼ì œ: IITP 2025-001
   - ì˜ˆìƒ ì ìˆ˜: 60-70ì 
   - ì‹¤ì œ ì ìˆ˜: -5ì 

   ì¬í˜„ ë°©ë²•:
   1. ëŒ€ì‹œë³´ë“œ â†’ ë§¤ì¹­ ì‹œì‘
   2. IITP 2025-001 ê³¼ì œ í™•ì¸
   ```
5. Click "í”¼ë“œë°± ë³´ë‚´ê¸°"

**Expected Results:**
- Submission succeeds within 2 seconds
- Success message: "âœ… í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤!"
- Modal auto-closes after 2 seconds
- Admin receives email notification within 5 minutes
  - Priority: HIGH (bug report)
  - Subject: "âš ï¸ HIGH PRIORITY New Feedback: BUG - ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜"

**Feedback to Capture:**
- Was submission process smooth?
- Are categories clear?

---

**7.2 Submit Feature Request**
1. Open feedback widget
2. Category: "ğŸ’¡ ê¸°ëŠ¥ ì œì•ˆ"
3. Title: "CSV ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥"
4. Description: "ë§¤ì¹­ ê²°ê³¼ë¥¼ CSVë¡œ ë‚´ë³´ë‚¼ ìˆ˜ ìˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. Excelì—ì„œ ë¶„ì„í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤."
5. Submit

**Expected Results:**
- Priority: MEDIUM (feature request)
- Admin email subject: "ğŸ“ New Feedback: FEATURE_REQUEST - CSV ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥"

---

**7.3 Test Anonymous Feedback (Not Logged In)**
1. Log out
2. Open feedback widget
3. Submit feedback
4. Verify:
   - Submission still works
   - Notice: "ğŸ’¡ í”¼ë“œë°±ì€ ìµëª…ìœ¼ë¡œë„ ì œì¶œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹µë³€ì„ ì›í•˜ì‹œë©´ ë¡œê·¸ì¸ í›„ ì œì¶œí•´ ì£¼ì„¸ìš”."

**Expected Results:**
- Anonymous feedback accepted
- userId = null in database
- Admin email shows "User: Anonymous"

---

## Scenario 8: Performance & Responsiveness

### Objective
Measure user-perceived performance across all features.

### Prerequisites
- Completed organization profile

### Steps

**8.1 Dashboard Load Time**
1. Clear browser cache
2. Navigate to: https://connect.kr/dashboard
3. Measure "Time to First Paint" (TTFP)
4. Measure "Time to Interactive" (TTI)

**Expected Results:**
- TTFP: <1 second (target), <2 seconds (acceptable)
- TTI: <2 seconds (target), <3 seconds (acceptable)

**Tools:**
- Chrome DevTools â†’ Lighthouse
- Network tab â†’ Disable cache, throttle to "Fast 3G"

---

**8.2 Match Generation Speed**
1. Click "ë§¤ì¹­ ì‹œì‘"
2. Measure time from click to results displayed

**Expected Results:**
- P50: <2 seconds
- P95: <3 seconds

**Test Cases:**
- With cache: <1 second
- Without cache: <3 seconds

---

**8.3 AI Explanation (Uncached)**
1. Clear Redis cache
2. Generate AI explanation
3. Measure response time

**Expected Results:**
- P50: <3 seconds
- P95: <5 seconds

---

**8.4 AI Explanation (Cached)**
1. Generate explanation second time (same match)
2. Measure response time

**Expected Results:**
- P50: <100ms
- P95: <200ms

---

**8.5 Q&A Chat Message**
1. Send Q&A chat message
2. Measure time from send to AI response

**Expected Results:**
- P50: <3 seconds
- P95: <5 seconds

---

**8.6 Overall Responsiveness Assessment**
Rate overall platform responsiveness:
- [ ] Fast (everything feels instant)
- [ ] Acceptable (some delays but not frustrating)
- [ ] Slow (frequent waiting, frustrating)

**Feedback to Capture:**
- Slowest feature?
- Most responsive feature?
- Any features feel "stuck" or unresponsive?

---

## Scenario 9: Mobile Experience

### Objective
Test usability on mobile devices.

### Prerequisites
- iOS Safari or Android Chrome

### Steps

**9.1 Mobile Dashboard**
1. Access dashboard on mobile (iPhone/Android)
2. Verify:
   - Layout responsive (no horizontal scroll)
   - Match cards readable
   - Touch targets â‰¥44px (easy to tap)
   - No overlapping elements

**Expected Results:**
- Mobile-optimized layout
- Readable text (font size â‰¥14px)
- Easy navigation

---

**9.2 Mobile AI Chat**
1. Open Q&A chatbot on mobile
2. Type question using mobile keyboard
3. Verify:
   - Chat input not covered by keyboard
   - Scroll works smoothly
   - Copy/paste functional

**Expected Results:**
- Keyboard doesn't obscure input
- Smooth scrolling
- No layout breaks

---

**9.3 Mobile Feedback Widget**
1. Open feedback widget on mobile
2. Verify:
   - Modal fits screen
   - Textarea resizable
   - Submit button accessible

**Expected Results:**
- Full modal visible (no cutoff)
- Form usable

---

## Scenario 10: Edge Cases & Error Handling

### Objective
Test platform behavior under error conditions.

### Steps

**10.1 Slow Network (Throttle to "Slow 3G")**
1. Chrome DevTools â†’ Network â†’ Throttle: Slow 3G
2. Generate matches
3. Verify:
   - Loading indicators shown
   - Timeout handling (max 30 seconds)
   - Error message if timeout

**Expected Results:**
- Clear loading state
- Graceful timeout handling
- Retry option

---

**10.2 API Error (500 Response)**
Contact admin to trigger test error.

**Expected Results:**
- Error message: "ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
- Retry button
- Error logged to monitoring

---

**10.3 Invalid Input (Injection Attack)**
1. Try SQL injection in search:
   ```
   '; DROP TABLE users; --
   ```
2. Try XSS in feedback:
   ```html
   <script>alert('XSS')</script>
   ```

**Expected Results:**
- Input sanitized (no code execution)
- Safe error message

---

## Summary & Reporting

After completing scenarios, submit feedback via:
1. **In-app feedback widget** (preferred)
2. **Email**: support@connect.kr
3. **Beta Slack channel** (if invited)

**Feedback Format:**
- Scenario number
- Pass/Fail
- Issues found
- Severity (Critical / High / Medium / Low)
- Screenshots (if applicable)

**Thank you for beta testing Connect! ğŸš€**

Your feedback is invaluable for our January 1, 2026 launch.
