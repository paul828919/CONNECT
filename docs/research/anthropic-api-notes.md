# Anthropic Claude API Research Notes
**Date**: October 9, 2025
**Purpose**: Comprehensive API understanding for Week 3-4 AI Integration

---

## ğŸ“š API Overview

### Model: Claude Sonnet 4.5
- **Model ID**: `claude-sonnet-4-5-20250929`
- **Context Window**: 200K tokens input, 8K tokens output
- **Strengths**: Balanced speed + quality, excellent for production
- **Korean Support**: Native multilingual support, strong Korean capabilities

### API Endpoint
- **Base URL**: `https://api.anthropic.com/v1/messages`
- **Authentication**: `x-api-key` header with API key
- **Content-Type**: `application/json`

---

## ğŸ”‘ Authentication & Setup

### API Key Format
```
sk-ant-api03-[base64_characters]
```

### Environment Variable
```bash
export ANTHROPIC_API_KEY="sk-ant-api03-..."
```

### SDK Initialization
```typescript
import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});
```

---

## ğŸ“Š Rate Limits & Pricing

### Tier 1 (Default)
- **Requests**: 50 per minute
- **Tokens**: 40,000 per minute (input + output combined)
- **Daily**: No hard daily limit, but billed monthly

### Tier 2 (After $40 deposit)
- **Requests**: 1,000 per minute
- **Tokens**: 80,000 per minute
- **Recommended for**: Production with >100 daily active users

### Pricing (Claude Sonnet 4.5)
- **Input**: $3.00 per 1M tokens
- **Output**: $15.00 per 1M tokens
- **Cache Writes**: $3.75 per 1M tokens (prompt caching)
- **Cache Reads**: $0.30 per 1M tokens (90% savings)

### Cost Calculator (KRW, 1 USD = â‚©1,300)
| Usage Type | Per 1K Tokens (KRW) | Per Request (Estimate) |
|------------|---------------------|------------------------|
| Input (500 tokens) | â‚©1.95 | â‚©0.98 |
| Output (200 tokens) | â‚©19.50 | â‚©3.90 |
| **Total per request** | - | **â‚©4.88** |

**Daily Budget Projection** (500 requests/day):
- Without cache: â‚©2,440 (~â‚©73,200/month)
- With 50% cache hit: â‚©1,220 (~â‚©36,600/month)
- Target: <â‚©50,000/day â†’ ~10,246 requests/day capacity

---

## ğŸ› ï¸ API Parameters

### Essential Parameters

#### `model` (required)
```typescript
model: "claude-sonnet-4-5-20250929"
```

#### `messages` (required)
```typescript
messages: [
  {
    role: "user",
    content: "Your question here"
  }
]
```

#### `max_tokens` (required)
```typescript
max_tokens: 1024  // Output limit, adjust per use case
```

### Optional Parameters

#### `system` (highly recommended)
```typescript
system: "You are an expert in Korean R&D grants..."
```
- Sets AI's role, expertise, and tone
- Separate from `messages` array
- Korean works perfectly here

#### `temperature` (default: 1.0)
```typescript
temperature: 0.7
```
- **0.0-0.3**: Deterministic, factual (match explanations)
- **0.5-0.7**: Balanced, conversational (Q&A chat) âœ… Recommended
- **0.8-1.0**: Creative, varied (not recommended for grants)

#### `top_p` (default: 1.0)
```typescript
top_p: 0.9
```
- Alternative to temperature
- Use either temperature OR top_p, not both
- 0.9 = slightly more focused than temperature 0.7

#### `top_k` (default: null)
```typescript
top_k: 40
```
- Limits vocab sampling
- Useful for preventing hallucinations
- Not typically needed with good prompts

#### `stop_sequences` (optional)
```typescript
stop_sequences: ["</response>", "\n\nHuman:"]
```
- Stops generation at specific strings
- Useful for structured outputs

#### `stream` (default: false)
```typescript
stream: true
```
- Enables streaming responses
- Better UX for long responses
- Requires different handling (SSE)

---

## ğŸ“ Message API Structure

### Basic Request
```typescript
const message = await anthropic.messages.create({
  model: "claude-sonnet-4-5-20250929",
  max_tokens: 1024,
  system: "ë‹¹ì‹ ì€ í•œêµ­ ì •ë¶€ R&D ê³¼ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
  messages: [
    {
      role: "user",
      content: "TRL 7 ìˆ˜ì¤€ì˜ ê¸°ìˆ ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
    }
  ]
});
```

### Response Structure
```typescript
{
  id: "msg_01XYZ...",
  type: "message",
  role: "assistant",
  content: [
    {
      type: "text",
      text: "TRL 7ì€ ì‚¬ì—…í™” ì‹œì œí’ˆ ì œì‘ ë‹¨ê³„ë¡œ..."
    }
  ],
  model: "claude-sonnet-4-5-20250929",
  stop_reason: "end_turn",  // or "max_tokens", "stop_sequence"
  stop_sequence: null,
  usage: {
    input_tokens: 45,
    output_tokens: 128
  }
}
```

### Error Handling
```typescript
try {
  const message = await anthropic.messages.create({ ... });
} catch (error) {
  if (error.status === 429) {
    // Rate limit exceeded
  } else if (error.status === 401) {
    // Invalid API key
  } else if (error.status === 400) {
    // Bad request (check parameters)
  }
}
```

---

## ğŸ¯ Best Practices for Korean R&D Use Case

### 1. System Prompt Design
```typescript
system: `ë‹¹ì‹ ì€ Connect í”Œë«í¼ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì—­í• :
- í•œêµ­ ì •ë¶€ R&D ê³¼ì œ ì „ë¬¸ ìƒë‹´
- ê¸°ì—…ì˜ ê³¼ì œ ë§¤ì¹­ ê²°ê³¼ ì„¤ëª…
- ê¸°ìˆ ì„±ìˆ™ë„(TRL), ì¸ì¦ ìš”ê±´, ì˜ˆì‚° ë“±ì— ëŒ€í•œ ì§ˆë¬¸ ë‹µë³€

í†¤:
- ì „ë¬¸ì ì´ë©´ì„œ ì¹œê·¼í•œ ì¡´ëŒ“ë§ ì‚¬ìš©
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ëª…í™•íˆ ë°í˜
- ë²•ì  ì¡°ì–¸ íšŒí”¼ (ì¼ë°˜ ì•ˆë‚´ë§Œ ì œê³µ)

ì‘ë‹µ ê¸¸ì´:
- ê°„ê²°í•˜ê²Œ 2-3 ë¬¸ë‹¨ ì´ë‚´
- í•µì‹¬ë¶€í„° ë¨¼ì €, ìƒì„¸ ë‚´ìš©ì€ í•„ìš”ì‹œ
`
```

### 2. User Message Formatting
```typescript
// âœ… Good: Provide context in XML tags
messages: [
  {
    role: "user",
    content: `<company_context>
- ì‚°ì—…: ICT
- TRL: 7
- ì¸ì¦: ISMS-P ë³´ìœ 
</company_context>

<question>
IITP AI ìœµí•© ê³¼ì œì— ì í•©í•œê°€ìš”?
</question>`
  }
]

// âŒ Bad: No structure
messages: [
  { role: "user", content: "IITP AI ìœµí•© ê³¼ì œì— ì í•©í•œê°€ìš”?" }
]
```

### 3. Output Parsing with XML
```typescript
// Prompt: "ì‘ë‹µì„ XML í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”: <answer>ë‚´ìš©</answer>"

const response = message.content[0].text;
const match = response.match(/<answer>(.*?)<\/answer>/s);
if (match) {
  const answer = match[1].trim();
  // Use parsed answer
}
```

### 4. Token Optimization
```typescript
// Korean characters: ~2.5 characters per token
function estimateKoreanTokens(text: string): number {
  return Math.ceil(text.length / 2.5);
}

// Before sending request
const estimatedTokens = estimateKoreanTokens(systemPrompt + userMessage);
if (estimatedTokens > 8000) {
  // Truncate or summarize
}
```

---

## ğŸ”„ Streaming Responses

### Enable Streaming
```typescript
const stream = await anthropic.messages.create({
  model: "claude-sonnet-4-5-20250929",
  max_tokens: 1024,
  stream: true,
  messages: [{ role: "user", content: "..." }]
});

for await (const event of stream) {
  if (event.type === 'content_block_delta') {
    process.stdout.write(event.delta.text);
  }
}
```

### Benefits
- **UX**: User sees response immediately (perceived <500ms)
- **Engagement**: Feels more conversational
- **Cancellation**: Can stop expensive requests early

### When to Use
- âœ… Q&A chat (long responses)
- âŒ Match explanations (short, cacheable)

---

## ğŸ“¦ Prompt Caching (Coming Soon)

### How It Works
```typescript
system: [
  {
    type: "text",
    text: "ë‹¹ì‹ ì€ Connect AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤...",
    cache_control: { type: "ephemeral" }  // Cache this
  }
]
```

### Cost Savings
- **First request**: $3.75/1M tokens (cache write)
- **Subsequent requests**: $0.30/1M tokens (cache read)
- **Savings**: 90% on repeated system prompts

### Use Cases
- System prompt (same for all requests)
- Company profile context (same within session)
- Few-shot examples (static)

---

## ğŸš¨ Safety & Content Policy

### Prohibited Uses
- Legal advice (only general guidance)
- Medical diagnoses
- Financial investment advice
- Impersonation of government officials

### Our Compliance
âœ… **Allowed**: "ì¼ë°˜ì ìœ¼ë¡œ TRL 7 ì´ìƒì€ IITP ê³¼ì œì— ì í•©í•©ë‹ˆë‹¤" (general info)
âŒ **Not allowed**: "ê·€ì‚¬ëŠ” ë°˜ë“œì‹œ ì´ ê³¼ì œì— ì„ ì •ë  ê²ƒì…ë‹ˆë‹¤" (guarantee)

### Disclaimers to Include
```markdown
**ì•ˆë‚´**: ë³¸ ì •ë³´ëŠ” ì¼ë°˜ì ì¸ ì•ˆë‚´ì´ë©°,
ìµœì¢… ì‹ ì²­ ì „ ë°˜ë“œì‹œ ê³µê³ ë¬¸ì„ ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
```

---

## ğŸ§ª Testing Checklist

### Basic Functionality
- [ ] API key authentication works
- [ ] Korean text request/response successful
- [ ] Token usage tracked correctly
- [ ] Error handling (429, 401, 400)

### Korean Quality
- [ ] ì¡´ëŒ“ë§ (formal speech) natural
- [ ] Domain terminology accurate (TRL, ISMS-P, etc.)
- [ ] No English fallback in Korean responses
- [ ] Punctuation correct (ë§ˆì¹¨í‘œ, ì‰¼í‘œ)

### Performance
- [ ] Response time <2 seconds (non-streaming)
- [ ] Streaming starts <500ms
- [ ] Rate limits respected (50 RPM)
- [ ] Token estimates accurate (Â±10%)

---

## ğŸ“š Key Documentation Links

1. **API Reference**: https://docs.anthropic.com/en/api/messages
2. **Prompt Engineering**: https://docs.anthropic.com/en/docs/prompt-engineering
3. **Rate Limits**: https://docs.anthropic.com/en/api/rate-limits
4. **Pricing**: https://www.anthropic.com/pricing
5. **Content Policy**: https://www.anthropic.com/legal/aup
6. **SDK (TypeScript)**: https://github.com/anthropics/anthropic-sdk-typescript

---

## ğŸ¯ Next Steps (Day 2-6)

### Day 2: Korean Terminology
- Create comprehensive glossary (TRL, certifications, grant types)
- Collect real grant examples for training data

### Day 3: Prompt Templates
- Match explanation prompt with XML structure
- Q&A chat prompt with conversation context

### Day 4: Cost Optimization
- Implement response caching (Redis)
- Token usage tracking and budget alerts

### Day 5: Conversation Memory
- Design conversation history storage
- Context window management (last 10 messages)

### Day 6: Final Review
- Integration checklist
- Risk assessment
- Ready to start Week 3-4 execution

---

**Research Completed**: October 9, 2025
**Key Findings**:
- Claude Sonnet 4.5 excellent for Korean R&D domain
- Temperature 0.7 optimal for conversational quality
- Prompt caching can reduce costs by 90%
- Streaming improves UX for Q&A chat
- Budget: â‚©36,600/month achievable with caching

**Status**: âœ… Day 1 API Research Complete
**Next**: Day 2 - Korean R&D Terminology Glossary
