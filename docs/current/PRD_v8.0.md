# CONNECT â€“ Product Requirements Document (PRD) v8.0

**Version:** 8.0 (Final Strategic Revision)
**Date:** 2025-10-08
**Status:** Production Ready - Strategic Pivot Complete
**Scope:** MVP Platform for Korea's R&D Commercialization Ecosystem

---

## Executive Summary

CONNECT transforms from a "grant discovery platform" to **Korea's complete R&D commercialization operating system**. The MVP focuses on **4 critical funding agencies** covering ~55% of Korea's R&D budget, with a hybrid software + services business model targeting **companies first** (research institutes as secondary supply-side).

**Key Strategic Changes in v8.0 (Final Revision):**
- **GTM Pivot**: Companies (primary paying customers) â†’ Research institutes (supply-side for consortium matching)
- **Business Model**: Software + services hybrid (services provide immediate cash flow + defensible moat)
- **Pricing Update**: â‚©49,000-69,000/month (sustainable) + services revenue (â‚©2-7M per engagement)
- **Data Moat**: Proprietary outcome tracking (win rates, cycle times) creates defensible competitive advantage
- **Compliance**: Off-budget services invoicing (legal compliance with R&D cost regulations)
- **Claims Discipline**: Honest expectations (200-500 active programs + 108K historical for patterns)

---

## 1. Product Vision & Strategy

### 1.1 Vision Statement
Enable Korean companies to efficiently discover, apply for, and win government R&D funding through intelligent matching, automated monitoring, and execution support services.

### 1.2 Strategic Positioning

**Primary Value Proposition:**
- **For Companies**: Complete R&D commercialization support (discovery â†’ application â†’ winning)
- **Vs. Manual Search**: Automated 4-agency monitoring + explainable matching
- **Vs. Generic AI** (ChatGPT â‚©25,000/month): Verified Korean R&D data + outcome intelligence
- **Vs. Consultants**: Software enables scale + services provide expertise (hybrid advantage)

**Unique Moats:**
1. **Proprietary Outcome Data**: Win rates, cycle times, success patterns (competitors lack this)
2. **Services Layer**: Consultants can't scale software, SaaS can't deliver expertise (we do both)
3. **Network Effects**: More users â†’ more outcome data â†’ better matching
4. **Compliance**: Off-budget invoicing structure prevents customer audit risk

### 1.3 Target Market (Revised GTM)

**Primary Target: Companies (90% of revenue)**
- **Size**: 10,000+ SMEs seeking government R&D funding
- **Pain Point**: Don't know which grants exist, miss deadlines, low win rates (15-20%)
- **Budget Authority**: Can pay for software (â‚©49K-99K/month) + services (â‚©2-7M per project)
- **Peak Season**: January-March (80% of corporate funding announcements)
- **Initial Launch**: 50 beta users â†’ 500 users â†’ 1,000 users (if 70%+ retention)

**Secondary Target: Research Institutes (10% of revenue)**
- **Size**: 200+ institutes (95% founder network coverage)
- **Role**: Supply-side for consortium matching (not primary paying customers)
- **Value**: Free platform access in exchange for consortium partnership opportunities
- **Why Secondary**: Institutes don't need grant "discovery" (they have multi-year budgets)

**GTM Lesson Learned:**
Original PRD assumed research institutes would be primary customers (95% network = advantage). 
Reality: Research institutes don't pay for discovery (they already know their grants).
**Pivot**: Companies are primary paying customers. Use professor network for **company introductions**, not institute signups.

### 1.4 Revenue Model (Hybrid: Software + Services)

**Software Revenue (Subscription SaaS):**
- Pro: â‚©49,000/month (companies, individual users)
- Team: â‚©99,000/month (5 seats, for larger teams)
- Target: 140 paying users by Month 6 â†’ â‚©6.86M/month recurring

**Services Revenue (High-margin consulting):**
- Application review: â‚©2-3M per project
- Certification planning: â‚©3-5M per project
- Consortium formation: â‚©3-5M per project
- TRL advancement consulting: â‚©5-7M per project
- Target: 10 services engagements by Month 6 â†’ â‚©30-50M one-time

**Why Hybrid Model:**
1. **Immediate Cash Flow**: Services provide â‚©25M+ revenue from Month 1 (vs. waiting for MRR buildup)
2. **Sustainable Pricing**: â‚©49K-99K software pricing covers infrastructure costs
3. **Defensible Moat**: Competitors can't easily replicate services expertise
4. **Customer Success**: Services help customers win grants â†’ positive outcome data â†’ better matching
5. **Profitability**: Breaks even Month 1 (vs. Month 8+ with software-only model)

**Total Revenue Projection (Month 6):**
- Software: â‚©6.86M/month (140 Pro/Team users)
- Services: â‚©30-50M (10 engagements)
- **Total: â‚©200M cumulative by Month 6**

---

## 2. User Personas (2 Core Types)

### 2.1 Company Users (ê¸°ì—…) - PRIMARY PAYING CUSTOMERS

**Profile:**
- Seeking R&D funding for technology development and commercialization
- Business structure: 90% ë²•ì¸ (Corporate), 10% ê°œì¸ì‚¬ì—…ì (Sole Proprietorship)
- Decision makers: R&D Directors, CEOs (small companies), Business Development Managers
- Budget authority: Can approve â‚©49-99K/month software + â‚©2-7M services

**Pain Points (Critical):**
1. **Discovery Problem**: Don't know which grants exist, scattered across 4+ agency websites
2. **Deadline Anxiety**: Miss opportunities due to poor tracking (50% of missed grants)
3. **Eligibility Confusion**: Complex requirements (TRL, certifications, revenue caps) hard to understand
4. **Low Win Rates**: 15-20% success rate (vs. 25-35% with proper support)
5. **Application Quality**: First-time applicants lack experience writing winning proposals
6. **Consortium Formation**: Can't find partners, or find wrong partners (mismatch)

**Primary Needs:**
1. Automated monitoring of 4 major agencies (save 10+ hours/month)
2. Simple eligibility matching (avoid wasting time on ineligible grants)
3. Deadline reminders (7-day, 3-day, 1-day alerts)
4. Application review services (increase win rate by 10-15 percentage points)
5. Partner introductions for consortium requirements

**Jobs to Be Done:**
- **Discover**: Find relevant grants without manual website checking
- **Qualify**: Understand if my company is eligible before applying
- **Apply**: Submit high-quality application with competitive advantage
- **Win**: Maximize selection probability through professional support
- **Track**: Know application status and outcomes

### 2.2 Research Institute Users (ì—°êµ¬ì†Œ) - SUPPLY-SIDE (FREE TIER)

**Profile:**
- Multi-year R&D budgets aligned to national priorities
- Types: Government-funded institutes (KIST, ETRI, etc.), private research centers
- Strong network advantage: 95% of founder's contacts

**Pain Points:**
- Finding industry partners for applied research and commercialization
- Tech transfer barriers (companies don't know institute capabilities)
- Matching with companies at appropriate TRL levels

**Value Proposition (Free Platform Access):**
- Discover companies seeking consortium partners
- Showcase research capabilities and technologies
- Connect with companies for joint R&D projects
- Access to applied research funding opportunities

**Why Free?**
Research institutes don't need grant "discovery" (they have multi-year government budgets).
Their value to Connect: Supply-side for consortium matching (companies need institutes as partners).
Platform facilitates both sides: Companies find grants â†’ Companies find institute partners â†’ Institutes get commercialization opportunities.

---

## 3. MVP Features (8-Week Launch Plan)

### Phase 1: Foundation (Weeks 1-2)

#### 3.1 User Registration & Profiles

**Company Profile Fields (10 Required):**
1. Company name (ë²•ì¸ëª…/ìƒí˜¸ëª…)
2. Business registration number (ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸) - Encrypted AES-256-GCM
3. Business structure (ë²•ì¸/ê°œì¸ì‚¬ì—…ì)
4. Industry sector (ì‚°ì—… ë¶„ì•¼)
5. Employee count (ì§ì› ìˆ˜)
6. Annual revenue range (ì—°ë§¤ì¶œ ë²”ìœ„)
7. R&D experience (Yes/No)
8. Technology readiness level (TRL 1-9)
9. Primary contact person
10. Email + phone

**Research Institute Profile Fields (10 Required):**
1. Institute name (ê¸°ê´€ëª…)
2. Registration number
3. Institute type (government/private)
4. Research focus areas (ìµœëŒ€ 3ê°œ)
5. Annual R&D budget range
6. Number of researchers
7. Key technologies (ìµœëŒ€ 5ê°œ)
8. Collaboration history (Yes/No)
9. Primary contact person
10. Email + phone

#### 3.2 Funding Match Engine (Enhanced with Sector Gates)

**Core Matching Logic (Rule-Based with Eligibility Gates):**

```javascript
function calculateMatch(organization, fundingProgram) {
  let score = 0;
  let explanation = [];
  let blockedReasons = [];
  let warningReasons = [];
  
  // === ELIGIBILITY GATES (PASS/FAIL) ===
  
  // Gate 1: Organization type
  if (organization.type !== fundingProgram.targetType && fundingProgram.targetType !== 'both') {
    return { 
      score: 0, 
      passesEligibility: false,
      blockedReasons: ["ì§€ì› ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤"] 
    };
  }
  
  // Gate 2: TRL range (strict)
  if (organization.trl < fundingProgram.minTRL - 2 || organization.trl > fundingProgram.maxTRL + 2) {
    blockedReasons.push(`TRL ë²”ìœ„ ë¶ˆì¼ì¹˜: ê·€ì‚¬ TRL ${organization.trl}, ìš”êµ¬ TRL ${fundingProgram.minTRL}-${fundingProgram.maxTRL}`);
    return { score: 0, passesEligibility: false, blockedReasons };
  }
  
  // Gate 3: Sector-specific requirements
  if (fundingProgram.requiresISMS && !organization.hasISMSCert) {
    blockedReasons.push("ISMS-P ì¸ì¦ í•„ìˆ˜ (ë¯¸ë³´ìœ )");
    return { score: 0, passesEligibility: false, blockedReasons };
  }
  
  if (fundingProgram.requiresKC && !organization.hasKCCert) {
    blockedReasons.push("KC ì¸ì¦ í•„ìˆ˜ (ë¯¸ë³´ìœ )");
    return { score: 0, passesEligibility: false, blockedReasons };
  }
  
  // === SCORING (IF PASSES GATES) ===
  
  // Industry match (30 points)
  if (organization.industrySector === fundingProgram.targetIndustry) {
    score += 30;
    explanation.push("ì‚°ì—… ë¶„ì•¼ê°€ ê³¼ì œ ìš”êµ¬ì‚¬í•­ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤");
  } else if (isSimilarIndustry(organization.industrySector, fundingProgram.targetIndustry)) {
    score += 15;
    explanation.push("ìœ ì‚¬ ì‚°ì—… ë¶„ì•¼ì…ë‹ˆë‹¤");
    warningReasons.push("ì‚°ì—… ë¶„ì•¼ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤");
  }
  
  // TRL matching (20 points)
  if (organization.trl >= fundingProgram.minTRL && organization.trl <= fundingProgram.maxTRL) {
    score += 20;
    explanation.push(`ê¸°ìˆ  ì¤€ë¹„ ìˆ˜ì¤€(TRL ${organization.trl})ì´ ê³¼ì œ ìš”êµ¬ì‚¬í•­(TRL ${fundingProgram.minTRL}-${fundingProgram.maxTRL})ê³¼ ì™„ë²½íˆ ì¼ì¹˜í•©ë‹ˆë‹¤`);
  } else if (Math.abs(organization.trl - fundingProgram.minTRL) <= 1) {
    score += 10;
    explanation.push(`TRL ${organization.trl}ì´ ìš”êµ¬ ë²”ìœ„ì— ê·¼ì ‘í•©ë‹ˆë‹¤`);
    warningReasons.push("TRL ìƒí–¥ í•„ìš” ì—¬ë¶€ ê²€í†  í•„ìš”");
  }
  
  // Certifications (20 points)
  let certScore = 0;
  if (fundingProgram.requiresISMS && organization.hasISMSCert) {
    certScore += 10;
    explanation.push("ISMS-P ì¸ì¦ ë³´ìœ  (í•„ìˆ˜ ìš”ê±´ ì¶©ì¡±)");
  }
  if (fundingProgram.requiresKC && organization.hasKCCert) {
    certScore += 10;
    explanation.push("KC ì¸ì¦ ë³´ìœ  (í•„ìˆ˜ ìš”ê±´ ì¶©ì¡±)");
  }
  if (organization.hasISO9001) {
    certScore += 5;
    explanation.push("ISO 9001 ì¸ì¦ ë³´ìœ  (ì¶”ê°€ ê°€ì )");
  }
  score += Math.min(20, certScore);
  
  // Budget fit (15 points)
  if (organization.revenueRange === fundingProgram.targetRevenueRange) {
    score += 15;
    explanation.push("ì˜ˆì‚° ê·œëª¨ê°€ ê·€ì‚¬ì— ì í•©í•©ë‹ˆë‹¤");
  }
  
  // R&D Experience (15 points)
  if (organization.hasRdExperience) {
    score += 15;
    explanation.push("R&D ê²½í—˜ ë³´ìœ  (ì„ ì • ê°€ëŠ¥ì„± í–¥ìƒ)");
  } else {
    score += 7;
    explanation.push("R&D ê²½í—˜ ë¯¸ë³´ìœ  (ì²« ê³¼ì œ ì‹ ì²­ ê°€ëŠ¥)");
  }
  
  return { 
    score, 
    explanation, 
    passesEligibility: true,
    blockedReasons,
    warningReasons
  };
}
```

**Match Display (Enhanced):**
- Show top 10 matches per user (increased from 3)
- Match score (0-100) with visual indicator
- Estimated win probability (future ML model)
- Korean explanation of why matched
- Eligibility status: âœ… Eligible / âš ï¸ Warning / ğŸš« Blocked
- Link to agency announcement page
- Deadline countdown with urgency indicator
- "Save for later" + "Dismiss" buttons
- CTA: "ì‹ ì²­ ì¤€ë¹„í•˜ê¸°" (Request application review service)

#### 3.3 Agency Monitoring (4 Agencies - Hybrid Approach)

**Covered Agencies:**
1. **IITP** (ì •ë³´í†µì‹ ê¸°íší‰ê°€ì›) - ICT sector, ~15% of budget
2. **KEIT** (í•œêµ­ì‚°ì—…ê¸°ìˆ í‰ê°€ê´€ë¦¬ì›) - Industrial tech, ~12% of budget
3. **TIPA** (ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì›) - SME support, ~8% of budget
4. **KIMST** (í•´ì–‘ìˆ˜ì‚°ê³¼í•™ê¸°ìˆ ì§„í¥ì›) - Maritime tech

**Hybrid Data Collection Strategy:**

**Primary Source: NTIS API**
- **Coverage**: 108,798+ R&D programs (historical + current)
- **Purpose**: Pattern analysis, success rate benchmarking, historical trends
- **Schedule**: Daily at 8:00 AM KST
- **Status**: Phase 1 complete, production key arriving Oct 14, 2025
- **Value**: "ê·€ì‚¬ì™€ ìœ ì‚¬í•œ ì¡°ì§ì˜ í‰ê·  ì„ ì •ë¥ : 38%" (powered by 108K historical programs)

**Secondary Source: Playwright Web Scraping**
- **Coverage**: 200-500 active calls from 4 agencies (realistic current opportunities)
- **Purpose**: Real-time announcement monitoring
- **Schedule**: 
  - Normal: 2x daily (9:00 AM, 3:00 PM KST)
  - Peak (Jan-Mar): 4x daily (9:00 AM, 12:00 PM, 3:00 PM, 6:00 PM KST)
- **Rate Limiting**: 10 requests/minute per agency

**CRITICAL: Honest Claims (No "100K+ programs" marketing)**
- Homepage: "êµ­ë‚´ ì£¼ìš” 4ê°œ ê¸°ê´€ ìµœì‹  ê³µê³  200~500ê±´ (ë§¤ì¼ ì—…ë°ì´íŠ¸)"
- Subtext: "Plus: ì—­ëŒ€ R&D ê³¼ì œ 108,000+ ê±´ ì„±ê³µ íŒ¨í„´ ë¶„ì„"
- Why: Honest expectations â†’ higher retention (vs. overpromising â†’ disappointment â†’ churn)

#### 3.4 Email Notifications

**Notification Types:**
- New matching opportunity (within 1 hour of scraping, if score >60)
- Deadline reminder (7 days, 3 days, 1 day before)
- Weekly digest (Mondays 9am, summary of new opportunities)
- Outcome tracking reminder (after application deadline, request result update)

**User Controls:**
- Enable/disable notification types
- Set preferred notification time
- Minimum match score threshold (default: 60/100)
- Notification frequency (real-time, daily, weekly)

#### 3.5 Outcome Tracking System (Proprietary Data Moat)

**Purpose**: Create defensible competitive advantage through win rate intelligence

**Data Collection (Opt-in with PIPA Consent):**

Users voluntarily share:
1. **Application Status**: Applied (Yes/No), Application date
2. **Selection Result**: Won / Lost / Pending / Withdrawn
3. **Financial Data** (optional): Requested amount, Award amount
4. **Feedback**: Application difficulty (1-5), Match quality (1-5)

**Consent Requirements (PIPA Compliance):**
- âœ… Explicit checkbox: "Connectì˜ ë§¤ì¹­ ì •í™•ë„ í–¥ìƒì„ ìœ„í•´ ê³¼ì œ ì‹ ì²­ ê²°ê³¼ ë°ì´í„°ë¥¼ ê³µìœ í•©ë‹ˆë‹¤"
- âœ… Clear explanation: "ê·€ì‚¬ì˜ êµ¬ì²´ì ì¸ ë°ì´í„°ëŠ” ê³µê°œë˜ì§€ ì•Šìœ¼ë©°, ìµœì†Œ 5ê±´ ì´ìƒ ì§‘ê³„ëœ í†µê³„ë¡œë§Œ í™œìš©ë©ë‹ˆë‹¤"
- âœ… Opt-out anytime: Users can revoke consent in settings

**Data Usage (Privacy-Preserving):**
- Aggregate statistics only (minimum 5 data points required)
- Example: "ê·€ì‚¬ì™€ ìœ ì‚¬í•œ ì‚°ì—…(ICT) Ã— TRL(7-8) ì¡°ì§ì˜ IITP ì„ ì •ë¥ : 38%"
- Example: "í‰ê·  ì‹¬ì‚¬ ê¸°ê°„: 87ì¼"
- Individual results NEVER disclosed

**Competitive Moat:**
- Competitors lack outcome data (only public announcement data)
- Connect's advantage compounds: More users â†’ More outcome data â†’ Better predictions
- Year 1: Basic win rate stats
- Year 2: ML models for win probability prediction
- Year 3: Recommend specific improvements to increase selection probability

### Phase 2: Execution Support (Weeks 3-4)

#### 3.6 Sector Gate Checklists (ISMS-P + KC)

**Purpose**: Prevent ineligible applications (save user time + increase platform credibility)

**ISMS-P Checklist (for SaaS/AI companies):**

16-item checklist mapped to KISA requirements:
```
ì •ë³´ë³´í˜¸ ê´€ë¦¬ì²´ê³„ (4 items):
â˜ ì •ë³´ë³´í˜¸ ì •ì±… ìˆ˜ë¦½
â˜ ìœ„í—˜ ê´€ë¦¬ í”„ë¡œì„¸ìŠ¤
â˜ ë‚´ë¶€ ê°ì‚¬ ì²´ê³„
â˜ ì •ë³´ë³´í˜¸ ì±…ì„ì ì§€ì •

ì •ë³´ë³´í˜¸ ëŒ€ì±… (12 items):
â˜ ì ‘ê·¼ í†µì œ
â˜ ì•”í˜¸í™”
â˜ ë¡œê·¸ ê´€ë¦¬
... (12 items total)
```

**Readiness Score Calculation:**
- Each item: 6.25 points (16 items Ã— 6.25 = 100)
- Score 0-40: Not ready (6-12 months prep time)
- Score 40-70: Partially ready (3-6 months prep time)
- Score 70-85: Ready (minor gaps, 1-3 months)
- Score 85-100: Highly ready (apply immediately)

**CTA when score < 70:**
"ISMS-P ì¸ì¦ ê³„íš ìˆ˜ë¦½ ì„œë¹„ìŠ¤ (â‚©3-5M) - 3-6ê°œì›” ë‚´ ì¸ì¦ ì·¨ë“ ì§€ì›"

**KC Checklist (for Hardware/IoT companies):**

Document preparation checklist:
```
í•„ìˆ˜ ì„œë¥˜ (8 items):
â˜ ì œí’ˆ ì„¤ëª…ì„œ
â˜ íšŒë¡œë„ (PCB layout)
â˜ ë¶€í’ˆ ë¦¬ìŠ¤íŠ¸ (BOM)
â˜ ì‚¬ìš©ì ë§¤ë‰´ì–¼
â˜ ì‹œí—˜ ì„±ì ì„œ (Test report)
â˜ ê³µì¥ ì‹¬ì‚¬ ì¤€ë¹„ (Factory inspection readiness)
â˜ KC ë§ˆí¬ ì ìš© ê³„íš
â˜ ì í•©ì„± ì„ ì–¸ì„œ
```

**Testing Body Selection:**
- KTL (í•œêµ­ì‚°ì—…ê¸°ìˆ ì‹œí—˜ì›) - Most common
- KCL (í•œêµ­ê±´ì„¤ìƒí™œí™˜ê²½ì‹œí—˜ì—°êµ¬ì›) - Construction/building products
- KTC (í•œêµ­ê¸°ê³„ì „ê¸°ì „ìì‹œí—˜ì—°êµ¬ì›) - Mechanical/electrical products

**Readiness Score + Estimated Cost:**
- Score 0-40: Not ready, â‚©5-10M + 3-6 months
- Score 40-70: Partially ready, â‚©3-7M + 2-4 months
- Score 70-100: Ready, â‚©2-5M + 1-2 months

#### 3.7 Procurement Readiness Calculator (ê³µê³µì¡°ë‹¬ ì¤€ë¹„ë„)

**Purpose**: Help companies qualify for procurement-track funding (í˜ì‹ ì œí’ˆ ì§€ì •, ìš°ìˆ˜ì œí’ˆ ì„ ì •)

**Scoring Model (0-100 points):**

1. **Product Maturity (30 points)**
   - TRL 9: 30 points (fully commercialized)
   - TRL 8: 20 points (system complete, tested)
   - TRL 7: 10 points (prototype demonstrated)
   - TRL <7: 0 points (not ready for procurement)

2. **Certifications (30 points)**
   - KC certification: 15 points
   - ISO 9001: 10 points
   - ISMS-P: 5 points (bonus for SaaS)

3. **Track Record (20 points)**
   - 3+ government R&D projects: 20 points
   - 1-2 projects: 10 points
   - 0 projects: 0 points

4. **Quality System (20 points)**
   - Product warranty (1+ years): 7 points
   - A/S infrastructure: 7 points
   - Technical support team: 6 points

**Gap Analysis Output:**

Example for company with 58/100 score:
```
ì´ì : 58/100 - ë¶€ë¶„ì ìœ¼ë¡œ ì¤€ë¹„ë¨

ì£¼ìš” ê°­:
1. TRL ìƒí–¥ í•„ìš” (í˜„ì¬ TRL 7 â†’ TRL 8+ í•„ìš”)
   - í•´ê²° ê¸°ê°„: 6-12ê°œì›”
   - ì˜ˆìƒ ë¹„ìš©: â‚©50-100M

2. KC ì¸ì¦ ë¯¸ë³´ìœ 
   - í•´ê²° ê¸°ê°„: 3-6ê°œì›”
   - ì˜ˆìƒ ë¹„ìš©: â‚©5-10M

3. ì •ë¶€ R&D ì‹¤ì  ë¶€ì¡± (0ê±´ â†’ 1ê±´+ í•„ìš”)
   - í•´ê²° ê¸°ê°„: 1ë…„
   - ë¹„ìš©: ê³¼ì œ ìˆ˜í–‰ ë¹„ìš©

ê¶Œì¥ ì¡°ì¹˜:
1. ë¨¼ì € ê¸°ìˆ  ê°œë°œ R&D ê³¼ì œ ì‹ ì²­ (TRL ìƒí–¥)
2. KC ì¸ì¦ ì·¨ë“ ë³‘í–‰
3. 1-2ë…„ í›„ ê³µê³µì¡°ë‹¬ ì‚¬ì—… ì‹ ì²­
```

**CTA for Services:**
- "TRL ìƒí–¥ ì»¨ì„¤íŒ… ì„œë¹„ìŠ¤ (â‚©5-7M)"
- "ì¸ì¦ ê³„íš ìˆ˜ë¦½ ì„œë¹„ìŠ¤ (â‚©3-5M)"

#### 3.8 Partner Discovery & Consortium Builder

**Search Capabilities:**
- Filter by organization type (company/institute)
- Filter by technology/industry
- Filter by TRL level (find partners at complementary TRL)
- Text search (Korean)
- View public profiles

**Contact Request:**
- Send introduction request with pre-filled templates
- Message: "ì•ˆë…•í•˜ì„¸ìš”, [ê³¼ì œëª…] ì»¨ì†Œì‹œì—„ êµ¬ì„±ì„ ìœ„í•´ ì—°ë½ë“œë¦½ë‹ˆë‹¤..."
- Response tracking dashboard
- Success rate: Track accepted vs. declined requests

**Basic Consortium Builder:**
- Create consortium project
- Assign roles: ì£¼ê´€ê¸°ê´€ (Lead) / ì°¸ì—¬ê¸°ê´€ (Partner)
- Simple budget split calculator
- Export member list for application
- Track consortium formation success (outcome data)

### Phase 3: Subscription & Services (Weeks 5-6)

#### 3.9 Payment Integration (Toss Payments)

**Subscription Plans:**

| Plan | Monthly | Annual | Features |
|------|---------|--------|----------|
| **Free** | â‚©0 | â‚©0 | 10 matches/month, 4 agencies, basic alerts |
| **Pro** | â‚©49,000 | â‚©49,000/mo (â‚©588,000/year) | Unlimited matches, real-time alerts, sector gates, outcome data |
| **Team** | â‚©99,000 | â‚©99,000/mo (â‚©1,188,000/year) | Pro + 5 seats, consortium tools, priority support |

**Beta Pricing (First 50 users):**
- â‚©4,900/month for first 30 days (promotional rate)
- After 30 days: Auto-upgrade to Pro (â‚©49,000/month) with 7-day advance notification
- Generates testimonials + early revenue

**Pricing Rationale:**
- â‚©49,000/month = Sustainable (covers infrastructure + support)
- vs. â‚©12,900 original: Too low, would require external funding
- vs. â‚©25,000 (ChatGPT): Competitive for specialized Korean R&D data
- Break-even: ~50 Pro users (â‚©2.45M/month covers server + 1 developer)

**Toss Payments Implementation:**
- Billing key method for recurring subscriptions
- Auto-charge monthly on `subscriptions.nextBillingDate`
- Failed payment handling: 3 retries over 7 days â†’ Downgrade to Free
- Tax invoice generation for corporate users (ì„¸ê¸ˆê³„ì‚°ì„œ)
- Webhook integration for real-time payment status updates

#### 3.10 Services Catalog & Engagement Management

**Service Types:**

1. **Application Review Service (â‚©2-3M)**
   - **Target**: Companies preparing to apply for grants
   - **Deliverables**:
     - Detailed review of ì—°êµ¬ê³„íšì„œ (research plan)
     - Scoring: Technology (40pts), Commercialization (30pts), Team (30pts)
     - 3-5 specific improvement recommendations
     - Re-review after revision (1 round included)
   - **Timeline**: 7-10 business days
   - **Success metric**: 10-15% win rate improvement

2. **Certification Planning (â‚©3-5M)**
   - **Target**: Companies needing ISMS-P or KC certification
   - **Deliverables**:
     - Gap analysis report
     - Implementation roadmap (Gantt chart)
     - Checklist of required documents
     - Vendor recommendations (testing bodies, consultants)
     - Budget estimate
   - **Timeline**: 2-3 weeks
   - **Success metric**: Client gets certified within 6 months

3. **Consortium Formation (â‚©3-5M)**
   - **Target**: Companies needing partners for joint R&D
   - **Deliverables**:
     - Partner search (5 qualified candidates)
     - Introduction facilitation (warm intros via network)
     - Consortium agreement template
     - Budget split recommendations
   - **Timeline**: 3-4 weeks
   - **Success metric**: Successful consortium formed

4. **TRL Advancement Consulting (â‚©5-7M)**
   - **Target**: Companies needing to progress from prototype to commercialization
   - **Deliverables**:
     - TRL assessment report
     - Technology development roadmap
     - Required validation tests
     - Commercialization strategy
   - **Timeline**: 4-6 weeks
   - **Success metric**: TRL increased by 1-2 levels within 12 months

**CRITICAL: Off-Budget Services Invoicing**

**Legal Requirement (êµ­ê°€ì—°êµ¬ê°œë°œì‚¬ì—… ì—°êµ¬ê°œë°œë¹„ ì‚¬ìš© ê¸°ì¤€):**
- Connect services are **business development costs** (ì‚¬ì—…ê°œë°œë¹„)
- **CANNOT** be included in government R&D project budgets (ì—°êµ¬ê°œë°œë¹„)
- Must be invoiced separately from R&D project costs
- Must be paid from company's operating budget (ìš´ì˜ë¹„)

**MSA Terms (Service Agreement Clause):**
```
ì œ4ì¡° (ì„œë¹„ìŠ¤ ë¹„ìš© ì²­êµ¬)
ë³¸ ì•½ê´€ ì œ4ì¡° ì œ2í•­ì— ëª…ì‹œëœ ë¶€ê°€ ì„œë¹„ìŠ¤ëŠ” ê¸°ì—…ì˜ ì‚¬ì—…ê°œë°œ ë¹„ìš©ìœ¼ë¡œ ì²­êµ¬ë˜ë©°,
ì •ë¶€ R&D ê³¼ì œ ì—°êµ¬ê°œë°œë¹„ ì˜ˆì‚°ì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ë²•ì  ê·¼ê±°:
- ã€Œêµ­ê°€ì—°êµ¬ê°œë°œì‚¬ì—… ì—°êµ¬ê°œë°œë¹„ ì‚¬ìš© ê¸°ì¤€ã€ (IITP ê³ ì‹œ ì œ2025-02í˜¸)
- ì—°êµ¬ê°œë°œë¹„ëŠ” ì§ì ‘ë¹„(ì¸ê±´ë¹„, ì—°êµ¬ì¬ë£Œë¹„, ì—°êµ¬í™œë™ë¹„ ë“±)ì™€ ê°„ì ‘ë¹„ë¡œë§Œ êµ¬ì„±
- ì¼ë°˜ ì»¨ì„¤íŒ… ë¹„ìš©ì€ ì—°êµ¬ê°œë°œë¹„ ì‚¬ìš© ê¸°ì¤€ì— í¬í•¨ë˜ì§€ ì•ŠìŒ
```

**Why This Matters:**
- Protects customers from audit risk (ê³¼ì œë¹„ ë¶€ì ì • ì§‘í–‰)
- Prevents Connect legal liability (ë¶ˆë²• ìš©ì—­ ì œê³µ)
- Ensures sustainable business model (customers use company budget, not grant budget)

**Customer Communication:**
- Clearly explain during sales: "ì´ ì„œë¹„ìŠ¤ëŠ” ê·€ì‚¬ì˜ ìš´ì˜ ì˜ˆì‚°ìœ¼ë¡œ ê²°ì œë©ë‹ˆë‹¤"
- Invoice separately from any R&D projects
- FAQ: "ë¶€ê°€ ì„œë¹„ìŠ¤ ë¹„ìš©ì€ R&D ì˜ˆì‚°ì— ë„£ì„ ìˆ˜ ìˆë‚˜ìš”? â†’ ì•„ë‹ˆìš”"

#### 3.11 Usage Analytics Dashboard

**User Metrics:**
- Matches viewed this month (vs. last month trend)
- Applications started (outcome tracking)
- Partner connections made
- Profile completeness score (0-100)
- Estimated win probability (based on similar organizations)

**Outcome Insights:**
- "ê·€ì‚¬ì™€ ìœ ì‚¬í•œ ì¡°ì§ì˜ í‰ê·  ì„ ì •ë¥ : 38%"
- "í‰ê·  ì‹¬ì‚¬ ê¸°ê°„: 87ì¼"
- "Most successful sectors: ICT (45%), Industrial tech (32%)"

---

## 4. Technical Architecture (Docker-Native)

### 4.1 Production Server Specifications

**Target Hardware:**
- CPU: Intel i9-12900K (16 cores / 24 threads)
- RAM: 128GB DDR4
- Storage: 1TB NVMe SSD
- Network: KT Broadband (164 Mbps up / 325 Mbps down)
- OS: Ubuntu 22.04 LTS

**Performance Targets:**
- Support 500-1,500 concurrent users
- API response time: < 500ms (P95)
- Match generation: < 3 seconds for top 10 results
- System uptime: > 99.9% during peak season (Jan-March) - **HOT STANDBY REQUIRED**

**Hot Standby (Peak Season Insurance):**
- **Why**: January-March = 80% of annual funding announcements, 27 hours downtime = 50+ users miss deadlines = brand destroyed
- **Setup**: Second i9-12900K server, PostgreSQL streaming replication (<5 min RPO), automated failover (<15 min RTO)
- **Cost**: â‚©600K/month Ã— 3 months = â‚©1.8M (vs. â‚©10-50M potential revenue loss)
- **ROI**: Prevents catastrophic failure during peak season

### 4.2 Database Schema (Enhanced)

**New Tables for Services & Outcomes:**

```sql
-- Grant Outcomes (Proprietary Data Moat)
CREATE TABLE grant_outcomes (
  id UUID PRIMARY KEY,
  organization_id UUID REFERENCES organizations(id),
  funding_program_id UUID REFERENCES funding_programs(id),
  funding_match_id UUID REFERENCES funding_matches(id),
  
  -- Application tracking
  applied BOOLEAN DEFAULT FALSE,
  applied_date DATE,
  application_method VARCHAR(50),
  
  -- Result tracking
  result VARCHAR(20), -- 'won', 'lost', 'pending', 'withdrawn'
  decision_date DATE,
  
  -- Financial data (opt-in)
  requested_amount_krw BIGINT,
  award_amount_krw BIGINT,
  award_amount_shared BOOLEAN DEFAULT FALSE, -- User consent
  
  -- Calculated metrics
  cycle_days INTEGER, -- decision_date - applied_date
  
  -- User feedback
  difficulty_rating INTEGER CHECK (difficulty_rating BETWEEN 1 AND 5),
  match_quality_rating INTEGER CHECK (match_quality_rating BETWEEN 1 AND 5),
  feedback_text TEXT,
  
  -- Privacy consent (PIPA)
  allow_aggregate_analytics BOOLEAN DEFAULT FALSE,
  consent_given_at TIMESTAMP,
  
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Privacy-preserving aggregate view
CREATE VIEW aggregate_success_patterns AS
SELECT 
  fp.agency_id,
  o.industry_sector,
  o.trl_level,
  COUNT(*) as total_applications,
  SUM(CASE WHEN go.result = 'won' THEN 1 ELSE 0 END) as wins,
  ROUND(AVG(go.cycle_days), 0) as avg_cycle_days
FROM grant_outcomes go
JOIN organizations o ON go.organization_id = o.id
JOIN funding_programs fp ON go.funding_program_id = fp.id
WHERE go.allow_aggregate_analytics = TRUE
GROUP BY fp.agency_id, o.industry_sector, o.trl_level
HAVING COUNT(*) >= 5; -- Minimum 5 data points

-- Services
CREATE TABLE services (
  id UUID PRIMARY KEY,
  service_type VARCHAR(50), -- 'application_review', 'certification', 'consortium', 'trl'
  name_korean VARCHAR(255),
  description TEXT,
  base_price_krw INTEGER,
  typical_duration_days INTEGER,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Service Engagements
CREATE TABLE service_engagements (
  id UUID PRIMARY KEY,
  service_id UUID REFERENCES services(id),
  organization_id UUID REFERENCES organizations(id),
  user_id UUID REFERENCES users(id),
  
  status VARCHAR(20), -- 'requested', 'in_progress', 'delivered', 'completed', 'cancelled'
  agreed_price_krw INTEGER,
  
  project_description TEXT,
  requested_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  completed_at TIMESTAMP,
  
  -- Payment
  invoice_number VARCHAR(50),
  payment_received_at TIMESTAMP,
  
  -- Feedback
  satisfaction_rating INTEGER CHECK (satisfaction_rating BETWEEN 1 AND 5),
  
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Sector Gate Checklists
CREATE TABLE sector_gate_checklists (
  id UUID PRIMARY KEY,
  organization_id UUID REFERENCES organizations(id),
  
  -- ISMS-P checklist
  isms_checklist JSONB, -- Array of {id, item, completed}
  isms_readiness_score INTEGER DEFAULT 0,
  
  -- KC checklist
  kc_checklist JSONB,
  kc_readiness_score INTEGER DEFAULT 0,
  
  last_updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Procurement Readiness
CREATE TABLE procurement_readiness (
  id UUID PRIMARY KEY,
  organization_id UUID REFERENCES organizations(id),
  
  total_score INTEGER DEFAULT 0 CHECK (total_score BETWEEN 0 AND 100),
  
  -- Score breakdown
  product_maturity_score INTEGER,
  certification_score INTEGER,
  track_record_score INTEGER,
  quality_system_score INTEGER,
  
  -- Gaps
  gaps JSONB, -- Array of {item, timeToResolve, costToResolve}
  
  calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## 5. Pricing Strategy (Revised)

### 5.1 Tier Structure

| Plan | Monthly | Annual | Target User |
|------|---------|--------|-------------|
| **Beta** | â‚©4,900 | - | First 50 users (30-day promotional) |
| **Free** | â‚©0 | â‚©0 | Trial users (10 matches/month) |
| **Pro** | â‚©49,000 | â‚©49,000/mo | Active grant seekers (companies) |
| **Team** | â‚©99,000 | â‚©99,000/mo | Larger teams (5 seats) |

### 5.2 Feature Matrix

| Feature | Free | Pro | Team |
|---------|------|-----|------|
| **Matches/month** | 10 | Unlimited | Unlimited |
| **Agencies** | 4 | 4 | 4 |
| **Match explanations** | Basic | Detailed | Detailed + scoring |
| **Sector gates** | View only | Interactive | Interactive + consulting CTA |
| **Outcome data** | Limited | Full access | Full access + insights |
| **Procurement calculator** | No | Yes | Yes |
| **Partner search** | 5/month | 50/month | Unlimited |
| **Email notifications** | Weekly | Real-time | Real-time |
| **Support** | Community | Email <24h | Priority + phone |
| **Services discount** | 0% | 10% | 20% |

### 5.3 Revenue Projections (Revised)

**Month 3 Scenario:**
```
Software:
- Free tier:   50 users Ã— â‚©0      = â‚©0
- Pro tier:    50 users Ã— â‚©49,000 = â‚©2.45M
- Team tier:   10 users Ã— â‚©99,000 = â‚©990K
- Total MRR: â‚©3.44M

Services:
- 5 engagements Ã— â‚©3M avg = â‚©15M (one-time)

Total Month 3: â‚©3.44M (recurring) + â‚©15M (services) = â‚©18.44M
```

**Month 6 Scenario:**
```
Software:
- Free tier:  100 users Ã— â‚©0      = â‚©0
- Pro tier:   120 users Ã— â‚©49,000 = â‚©5.88M
- Team tier:   20 users Ã— â‚©99,000 = â‚©1.98M
- Total MRR: â‚©7.86M

Services:
- 10 engagements Ã— â‚©4M avg = â‚©40M (one-time)

Total Month 6: â‚©7.86M (recurring) + â‚©40M (services) = â‚©47.86M
Cumulative (Month 1-6): ~â‚©200M
```

**Year 1 Target:**
- Software MRR: â‚©15-20M/month
- Services: â‚©100-150M/year
- **Total ARR: â‚©280-390M**

### 5.4 Break-Even Analysis

**Monthly Costs:**
- Infrastructure: â‚©600K (server + backups)
- Founder salary: â‚©0 (reinvest)
- Services COGS: 30% of services revenue (â‚©900K-1.5M)
- **Total: â‚©1.5-2.1M/month**

**Break-Even:**
- Software only: 31 Pro users (â‚©1.52M) OR 16 Team users (â‚©1.58M)
- With services: Achieved Month 1 (â‚©25M services revenue far exceeds costs)

**Why Hybrid Model Works:**
- Services provide immediate cash flow (no waiting for MRR buildup)
- Software scales with low marginal cost
- Combined model is profitable from Day 1

---

## 6. Success Metrics & KPIs (Revised)

### 6.1 Acquisition Metrics

| Metric | Month 1 | Month 3 | Month 6 | Measurement |
|--------|---------|---------|---------|-------------|
| **Registered Users** | 50 | 110 | 240 | Cumulative signups |
| **Companies** | 45 | 100 | 220 | Company signups (90% target) |
| **Research Institutes** | 5 | 10 | 20 | Institute signups (10% target) |
| **Beta Conversion** | 80% | - | - | Beta â†’ Paying |

### 6.2 Engagement Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Profile Completion** | >90% | Completed all 10 fields |
| **Weekly Active Users** | >70% | Logged in last 7 days |
| **Matches Viewed** | 5+ per user/week | Average views |
| **Match Quality Rating** | >4.0/5.0 | User rating |
| **Outcome Tracking Opt-in** | >60% | Users who share results |

### 6.3 Revenue Metrics

| Metric | Target (Month 3) | Target (Month 6) | Measurement |
|--------|------------------|------------------|-------------|
| **MRR (software)** | â‚©3.4M | â‚©6.9M | Monthly recurring revenue |
| **Services revenue** | â‚©25M | â‚©50M | One-time project fees |
| **ARPU (software)** | â‚©49K | â‚©49K | Avg revenue per user |
| **LTV** | â‚©588K | â‚©588K | Annual value per customer |
| **CAC** | â‚©200K | â‚©150K | Cost to acquire customer |
| **LTV/CAC ratio** | 2.9x | 3.9x | Must be >3x for sustainability |
| **Churn rate** | <8% | <5% | Monthly churn |

### 6.4 Outcome Metrics (Proprietary Data Moat)

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Outcome tracking rate** | >60% | Users who log application results |
| **Win rate (all users)** | 20-25% | % of applications that win |
| **Win rate (with services)** | 30-40% | Users who used application review |
| **Avg cycle time** | <90 days | Application â†’ Decision |
| **Services satisfaction** | >4.5/5.0 | Post-engagement rating |

### 6.5 Operational Metrics

| Metric | Target | Alert Threshold |
|--------|--------|-----------------|
| **API Response Time (P95)** | <500ms | >1s |
| **System Uptime** | 99.9% (Jan-Mar) | <99.5% |
| **NTIS API Success Rate** | >95% | <90% |
| **Match Generation Time** | <3 seconds | >5 seconds |
| **Database Connections** | <150 | >180 |
| **CPU Usage** | <70% | >85% |
| **Memory Usage** | <80% | >90% |

---

## 7. Go-to-Market Strategy (Revised)

### 7.1 Beta Launch (Week 8-9)

**Target:** 50 beta users (45 companies, 5 research institutes)

**Company Acquisition Strategy:**
1. **Professor Network (Primary)**
   - Email 50 research institute contacts
   - Request 2-3 **company introductions** per contact (not institute signups)
   - Target: 30-45 warm company leads
   - Two-step process: Build rapport â†’ Request intro (not immediate ask)
   - Success rate: 50-60% (vs. 30% if asking immediately)

2. **Direct Outreach (Secondary)**
   - LinkedIn outreach to R&D directors at ICT companies
   - Webinar: "IITP R&D ì§€ì›ì‚¬ì—… ì™„ì „ ì •ë³µ" (30 attendees)
   - Beta user testimonials

**Beta Pricing:**
- â‚©4,900/month for first 30 days (promotional)
- After 30 days: Auto-upgrade to Pro (â‚©49,000/month) with 7-day notice
- Generates early revenue + testimonials

**Success Criteria:**
- 70%+ weekly active usage
- 4.0+ average match quality rating
- 25%+ request services consultation
- <3 critical bugs reported

### 7.2 Public Launch (Week 10)

**Target:** 500 registered users by Month 4

**Marketing Channels:**

1. **Content Marketing (SEO)**
   - Blog: "2025 IITP ê³¼ì œ ì‹ ì²­ ê°€ì´ë“œ"
   - Blog: "ì •ë¶€ R&D ê³¼ì œ ì„ ì •ë¥ ì„ ë†’ì´ëŠ” 5ê°€ì§€ ë°©ë²•"
   - Keywords: "ì •ë¶€ R&D ê³¼ì œ", "ê¸°ì—… ì—°êµ¬ê°œë°œ ì§€ì›ê¸ˆ", "IITP ê³µê³ "
   - Target: 100 users/month from organic search by Month 6

2. **Webinars (High-conversion)**
   - Monthly webinar: "ì •ë¶€ R&D ê³¼ì œ ì™„ì „ ì •ë³µ"
   - 30 attendees Ã— 30% conversion = 9 users/webinar
   - Target: 2 webinars/month = 18 users/month

3. **Partnership (Startup Accelerators)**
   - SparkLabs, FuturePlay, Primer (3 partnerships)
   - Offer 50% discount for their portfolio companies
   - Target: 50 users from partnerships by Month 6

4. **Referral Program**
   - Give: â‚©100,000 credit for successful referral
   - Get: Referred user gets Pro free for 1 month
   - Target: 20-30% of users refer at least 1 person

**Launch Pricing:**
- First 100 public users: â‚©4,900/month for 30 days
- After 30 days: â‚©49,000/month Pro pricing

### 7.3 Services GTM (Month 1+)

**Lead Generation:**
- In-app CTAs: "ì‹ ì²­ì„œ ê²€í† ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?"
- Email nurture: "ê·€ì‚¬ì™€ ìœ ì‚¬í•œ ì¡°ì§ì˜ ì„ ì •ë¥ : 38% â†’ ê²€í†  ì„œë¹„ìŠ¤ë¡œ 50%+"
- Webinar upsell: Offer 20% discount to attendees

**Sales Process:**
1. **Discovery Call** (30 min): Understand customer need, grant timeline
2. **Proposal** (2 days): Custom quote (â‚©2-7M), deliverables, timeline
3. **Contract Signing** (1 week): MSA + off-budget invoicing explanation
4. **Kickoff** (1 week after payment): Project start
5. **Delivery** (1-4 weeks): Depends on service type
6. **Follow-up** (Post-delivery): Request outcome tracking, testimonial

**Conversion Funnel:**
- 1,000 Pro users â†’ 100 consult requests â†’ 30 proposals â†’ 10 closed deals
- Conversion rate: 10% (request â†’ close)
- Target: 10 services engagements by Month 6 = â‚©30-50M

### 7.4 Expansion Gate (Month 4)

**Decision Point:** Expand to 1,000 users?

**Criteria:**
- âœ… 70%+ retention after 3 months
- âœ… NPS >50
- âœ… <5% monthly churn
- âœ… >â‚©10M/month revenue (software + services)
- âœ… <80% server resource utilization
- âœ… Positive unit economics (LTV/CAC >3x)

**If criteria met:**
- Increase marketing spend (â‚©5M/month)
- Hire: Full-stack developer (â‚©4-5M/month)
- Open public registration (no waitlist)
- Expand webinar frequency (2x/month â†’ 4x/month)

**If criteria NOT met:**
- Focus on retention improvements
- Iterate on match quality
- Enhance services delivery quality
- Optimize pricing (A/B test â‚©49K vs. â‚©69K)

---

## 8. Risk Management & Mitigation

### 8.1 Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Peak season infrastructure failure** | Medium (30%) | Critical | Hot standby server + 99.9% SLO + chaos day testing |
| **NTIS API changes/deprecation** | Low (10%) | High | Diversify with Playwright scraping + monitor API announcements |
| **Data breach (PIPA violation)** | Low (5%) | Critical | AES-256 encryption + explicit consent + annual security audit |
| **Payment processing failures** | Low (10%) | Medium | Toss Payments with retry logic + webhook monitoring |

**Detailed Mitigation: Hot Standby**
- **Trigger**: Primary server hardware failure during Jan-March
- **Impact**: 27 hours downtime = 50+ users miss deadlines = brand destroyed
- **Mitigation**:
  - Hot standby server operational by Dec 31
  - Automated failover script (<15min RTO)
  - PostgreSQL streaming replication (<5min RPO)
  - PagerDuty 24/7 monitoring + SMS alerts
  - Weekly health checks during Jan-Mar
- **Cost**: â‚©600K/month Ã— 3 months = â‚©1.8M
- **ROI**: Prevents â‚©10-50M revenue loss from churn

### 8.2 Business Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Low conversion (Freeâ†’Pro)** | Medium (40%) | High | Free tier validation (10 matches/month) + outcome tracking + referral program |
| **High churn (poor match quality)** | Medium (30%) | High | Sector gates + TRL filtering + outcome feedback loop |
| **Pricing too low (unsustainable)** | Low (20%) | High | A/B test â‚©49K vs â‚©69K + services revenue supplements |
| **Research institute GTM failure** | High (60%) | Medium | Flip to companies-first GTM + professors for intros only |
| **Competitor with VC funding** | Medium (40%) | Medium | Services moat + outcome data moat + network effects |

**Detailed Mitigation: Low Freeâ†’Pro Conversion**
- **Trigger**: <20% conversion rate after 60 days
- **Impact**: Revenue projections miss by 30-40%
- **Mitigation**:
  - Increase free tier to 10 matches/month (was 3)
  - Show outcome data: "Users like you have 38% win rate"
  - Email nurture: Days 7, 14, 30 with success stories
  - Referral incentive: Get Pro free for 1 month per referral
- **Early warning**: Track conversion funnel weekly
- **Decision point**: If <25% by Week 8 â†’ Increase free tier to 15 matches

**Detailed Mitigation: High Churn**
- **Trigger**: >10% monthly churn in first 3 months
- **Impact**: Negative word-of-mouth kills growth
- **Root cause**: Users apply to mismatched grants â†’ rejected â†’ blame Connect
- **Mitigation**:
  - Sector gates (ISMS-P, KC/EMC) prevent ineligible applications
  - TRL gates block applications >2 levels away
  - Show "Estimated win probability: 35%" (manage expectations)
  - Outcome tracking creates feedback loop
  - Offer application review service (â‚©2-3M) before they apply
- **Early warning**: NPS survey at 30 days
- **Decision point**: If NPS <30 â†’ Pause growth, fix match quality

### 8.3 Competitive Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **VC-funded competitor launches** | Medium (40%) | High | Speed to market + proprietary outcome data |
| **NTIS builds their own matching** | Low (10%) | Critical | Services layer + user relationships |
| **Existing consultant pivots to platform** | Medium (30%) | Medium | Software + services hybrid (consultants can't scale software) |

**Detailed Mitigation: VC-Funded Competitor**
- **Scenario**: Competitor raises â‚©500M-1B, launches at â‚©29K/month (loss leader)
- **Their advantages**: More capital, larger team, aggressive marketing
- **Our advantages**:
  - 6-12 month head start (they need time to build)
  - Proprietary outcome data (win rates, cycle times) = moat
  - Services revenue funds operations (don't need VC)
  - Direct relationships with 50-100 beta customers
  - Network effects: More users â†’ more outcome data â†’ better matching
- **Counter-strategy**:
  - Build outcome data moat FAST (Month 1-6)
  - Focus on retention over acquisition (happy users don't switch)
  - Expand to services (competitors can't easily replicate)
  - Corporate partnerships create enterprise moat
- **When to worry**: If competitor announced funding >â‚©1B â†’ Accelerate services expansion

---

## 9. Development Timeline

### Pre-MVP: NTIS API Integration

**Phase 1: Complete** (October 6, 2025)
- âœ… All implementation complete and production-ready
- âœ… Comprehensive testing and validation
- âœ… Documentation (1,100+ line roadmap)

**Phases 2-5: Scheduled** (October 14, 2025+ after production API key)
- Phase 2: Production key integration (15-20 min)
- Phase 3: Hybrid scheduler (2-3 hours)
- Phase 4: Monitoring (1.5-2 hours)
- Phase 5: Deployment (1-2 hours)

### 8-Week MVP Timeline (Revised)

**Weeks 1-2: Foundation + Sector Gates**
- User authentication & profiles
- Enhanced matching engine with eligibility gates
- Sector gate checklists (ISMS-P, KC)
- Procurement readiness calculator

**Weeks 3-4: Data Pipeline + Outcome Tracking**
- 4-agency scraping (NTIS API + Playwright)
- Content change detection
- Outcome tracking system (PIPA-compliant)
- Email notifications

**Weeks 5-6: Services + Monetization**
- Services catalog & engagement management
- Toss Payments integration
- MSA with off-budget invoicing clause
- Usage analytics dashboard
- Partner search & consortium tools

**Weeks 7-8: Polish + Launch**
- Bug fixes & optimization
- Hot standby setup
- Beta user onboarding (50 users)
- Production deployment
- First services engagement

---

## 10. Competitive Advantages (Updated)

### 10.1 Why Users Choose Connect

1. **Automated Monitoring** - vs. manual checking of 4 agency websites (saves 10+ hours/month)
2. **Explainable Matching** - vs. generic AI recommendations (users understand why matched)
3. **Outcome Intelligence** - "38% win rate for similar companies" (proprietary data)
4. **Execution Support** - Application review services increase win rate by 10-15%
5. **Sector Gates** - Prevent ineligible applications (save time + improve credibility)
6. **Korean-Optimized** - ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ verification, Korean UI/UX, local payment methods
7. **Cost Efficiency** - â‚©49K vs. â‚©25K (ChatGPT) for specialized Korean R&D data

### 10.2 Moats (Defensible Competitive Advantages)

**1. Proprietary Outcome Data Moat**
- Competitors only have public announcement data
- Connect tracks win rates, cycle times, success patterns (opt-in user data)
- Advantage compounds: More users â†’ More outcome data â†’ Better predictions
- Timeline: Basic stats (Year 1) â†’ ML models (Year 2) â†’ Prescriptive recommendations (Year 3)

**2. Services Moat**
- Pure SaaS competitors can't deliver consulting expertise
- Pure consultants can't scale software
- Connect does both: Software enables reach, services provide depth
- Services create customer success â†’ Positive outcomes â†’ Better data â†’ Better matching

**3. Network Effects Moat**
- Companies need research institute partners (consortium requirements)
- Research institutes need industry partners (commercialization)
- Connect facilitates both sides (two-sided marketplace)
- More users â†’ More partnership opportunities â†’ Higher platform value

**4. Compliance Moat**
- Off-budget services invoicing (legal compliance)
- PIPA-compliant data collection (encrypted ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸)
- Competitors who violate regulations face shutdown risk

**5. Execution Moat**
- 95% research institute network (founder relationships)
- 6-12 month head start vs. competitors
- Peak season infrastructure (hot standby) ensures reliability
- Docker-native deployment (rapid iteration)

---

## Conclusion

Connect v8.0 represents a **complete strategic revision** from "grant discovery platform" to **Korea's R&D commercialization operating system**. 

**Key Success Factors:**
1. **Companies-first GTM** (primary paying customers, not research institutes)
2. **Hybrid business model** (software + services = profitable Month 1)
3. **Proprietary outcome data** (defensible moat vs. competitors)
4. **Sector gates + procurement calculator** (execution support, not just discovery)
5. **Honest claims** (200-500 active programs + 108K historical patterns)
6. **Off-budget services invoicing** (legal compliance + customer protection)
7. **Hot standby infrastructure** (99.9% SLA during peak season Jan-March)

**Financial Trajectory:**
- **Month 1**: â‚©28M (profitable immediately via services)
- **Month 3**: â‚©18M/month (â‚©3.4M MRR + â‚©15M services)
- **Month 6**: â‚©48M/month (â‚©7.9M MRR + â‚©40M services)
- **Cumulative Month 6**: â‚©200M+ revenue
- **Break-even**: Month 1 (vs. Month 8+ with software-only)

**Next Steps:**
1. Complete 12-week accelerated implementation (Oct 9, 2025 â†’ Jan 1, 2026)
2. Beta launch Week 8: 5-10 companies, expand to 20-30 by Week 9
3. First services engagement (â‚©2-5M) during beta period
4. Public launch: January 1, 2026 (Peak season timing)
5. Expansion gate: 1,000 users if 70%+ retention after 3 months

**Implementation Plan:**
- **Master Progress Tracker**: See `docs/plans/progress/MASTER-PROGRESS-TRACKER.md` (Complete status Oct 9 â†’ Jan 1, 2026)
- **Detailed Execution Plan**: See `docs/plans/EXECUTION-PLAN-MASTER.md` for day-by-day tasks
- **Progress Tracking**: See `docs/plans/progress/` for daily completion logs
- **Current Status**: See `IMPLEMENTATION-STATUS.md` at project root
- **Timeline**: 12 weeks from Oct 9, 2025 â†’ Jan 1, 2026 launch

**Critical Milestones:**
- Week 1-2 (Oct 9-22): Hot Standby Infrastructure (99.9% SLO capability)
- Week 3-4 (Oct 23-Nov 5): AI Integration (Claude Sonnet 4.5)
- Week 5-6 (Nov 6-19): Load Testing + Security Hardening
- Week 7-10 (Nov 20-Dec 17): 4-Week Beta Testing + Code Freeze
- Week 11-12 (Dec 18-31): Final Testing + Launch Preparation
- **Jan 1, 2026 00:00 KST**: Public Launch ğŸš€

**This is not a grant discovery tool. This is Korea's R&D commercialization operating system.**

---

**Document Status:** Final Strategic Revision - Implementation in Progress
**Next Review:** Week 10 Code Freeze (Dec 11, 2025) for GO/NO-GO decision
**Target Launch:** January 1, 2026 00:00 KST (Peak Season Aligned)

*End of PRD v8.0 - Final Strategic Revision*
