# CONNECT â€“ Product Requirements Document (PRD) v7.0

**Version:** 7.0
**Date:** 2025-09-28
**Status:** Production Ready - Enhanced Architecture
**Scope:** Innovation Ecosystem Platform for Korea's R&D Lifecycle

---

## Executive Summary

CONNECT is an explainable matching platform that accelerates Korea's innovation ecosystem by connecting Companies, Research Institutes, and Universities through the complete R&D lifecycle: Funding â†’ Collaboration â†’ Tech Transfer. Unlike generic AI tools (ChatGPT/Claude) that cost â‚©28,000/month, Connect provides verified, real-time Korean R&D opportunities with warm introductions and compliance automation for â‚©9,900/month.

**Key Changes in v7.0:**
- **Comprehensive Agency Coverage**: Expanded from 3 to 19 NTIS commissioning agencies
- **Optimized Data Collection**: Multi-daily scraping schedule for fresher data
- **Production-Grade Architecture**: Single-server deployment optimized for i9-12900K hardware
- **Enhanced Safety Measures**: PgBouncer, split Redis, atomic deployments
- **Development Workflow**: MacBook M4 â†’ Linux server deployment pipeline

---

## 1. Product Vision & Strategy

### 1.1 Vision Statement
Enable every Korean organization to accelerate innovation through intelligent matching across the complete R&D lifecycle with comprehensive, real-time opportunity coverage.

### 1.2 Strategic Positioning
- **Primary Competition**: ChatGPT/Claude/Gemini (â‚©28,000/month generic AI)
- **Secondary Competition**: Manual search on NTIS/SMTECH/K-Startup
- **Unique Value**: Complete 19-agency coverage + warm introductions + compliance automation

### 1.3 Target Market
- **Primary**: 10,000+ SMEs seeking government R&D funding (Jan-March rush)
- **Secondary**: 200+ research institutes, 400+ university labs
- **Total Addressable Market**: 10,600+ organizations in Korean R&D ecosystem

---

## 2. User Personas (3 Core Types)

### 2.1 Company Users (ê¸°ì—…)
- **Primary Need**: Funding for technology development
- **Secondary Need**: University/Institute collaboration for innovation
- **Pain Points**: Missing opportunities, complex requirements, no warm intros
- **Business Structure Split**: 90% Corporate (ë²•ì¸), 10% Sole Proprietorship (ê°œì¸ì‚¬ì—…ìž)
- **Decision Makers**: R&D Directors, Business Development Managers

### 2.2 Research Institute Users (ì—°êµ¬ì†Œ)
- **Primary Need**: Multi-year R&D budgets aligned to national priorities
- **Secondary Need**: Industry partners for commercialization
- **Pain Points**: Tech transfer barriers, finding industry applications
- **Types**: Government-funded institutes, private research centers

### 2.3 University Users (ëŒ€í•™)
- **Primary Need**: Research grants for labs and PIs
- **Secondary Need**: Industry collaboration for applied research
- **Pain Points**: Complex compliance (IRB/IACUC), TTO bottlenecks
- **Key Users**: Principal Investigators, TTO staff, graduate researchers

---

## 3. Core Features by Phase

### Phase 1: Funding Foundation (Weeks 1-2) - December Launch
**Goal**: Capture January-March government announcement rush with complete coverage

#### Features:
1. **Multi-Organization Registration**
   - 3 types supported (Company/Institute/University)
   - Business structure differentiation (ë²•ì¸/ê°œì¸ì‚¬ì—…ìž)
   - ì‚¬ì—…ìžë“±ë¡ë²ˆí˜¸ verification via Korean API
   - Organization profile templates by type

2. **Enhanced Funding Match Engine**
   - **Complete Coverage**: All 19 NTIS commissioning agencies
   - **Tiered Data Collection**: Fresh data from high-priority agencies 3x daily
   - **Transparent Logic**: Simple eligibility gates (organization type, TRL, budget)
   - **Explainable Results**: Top 5 matches with detailed explanations
   - **Korean-first UI** with English secondary

3. **Real-Time Announcement Calendar**
   - Visual timeline of upcoming deadlines
   - Filtered by organization type and program category
   - Email/Kakao notifications with customizable timing
   - Export to calendar applications
   - **Fresh Data**: Updated every 3-6 hours during business days

4. **Progressive Profile System**
   - 10-15 essential fields per organization type
   - Progressive disclosure to reduce cognitive load
   - Auto-save every change
   - Completion progress indicators

### Phase 2: Collaboration Layer (Weeks 3-4)
**Goal**: Enable consortium formation for complex R&D projects

#### Features:
1. **Partner Discovery**
   - Complementary capability matching
   - Technology-based search with Korean keyword optimization
   - Verified organization profiles with credibility scores
   - Contact request system with introduction templates

2. **Consortium Builder**
   - Smart partner suggestions based on program requirements
   - Role assignment (ì£¼ê´€ê¸°ê´€/ì°¸ì—¬ê¸°ê´€)
   - Budget allocation calculator with government guidelines
   - Collaboration history tracking

3. **Collaboration Workspace**
   - Secure document sharing with version control
   - Basic task management for project planning
   - Communication threads for each project
   - Legal template repository (user-provided only)

### Phase 3: Execution Tools (Weeks 5-6)
**Goal**: Reduce application time from days to hours

#### Features:
1. **Smart Checklists**
   - Auto-generated from program requirements
   - Deadline back-planning with milestone alerts
   - Document requirement mapping
   - Submission progress tracking

2. **Proposal Workspace**
   - Section templates based on common application formats
   - Collaborative editing with real-time sync
   - Version control and comment system
   - Export to required government formats

3. **Warm Introduction System**
   - Request â†’ Review â†’ Accept/Decline workflow
   - 72-hour SLA tracking with automated reminders
   - Introduction success metrics and feedback
   - Reputation system for active networkers

### Phase 4: Platform Polish (Weeks 7-8)
**Goal**: Revenue generation and retention optimization

#### Features:
1. **Payment Integration**
   - Toss Payments integration (Korean-optimized)
   - Free/Pro/Team subscription tiers
   - Usage-based metering for premium features
   - Corporate billing with ì„¸ê¸ˆê³„ì‚°ì„œ support

2. **Tech Transfer Marketplace** (Basic)
   - University/Institute IP listings
   - Technology search with semantic matching
   - Expression of interest system
   - Basic licensing workflow

3. **Analytics Dashboard**
   - Success rate tracking (user-reported)
   - Application timeline analytics
   - Collaboration network visualization
   - Performance benchmarking by organization type

---

## 4. Enhanced Technical Architecture

### 4.1 Production Server Specifications

**Target Hardware:**
- **CPU**: Intel i9-12900K (16 cores, 3.2-5.2 GHz)
- **RAM**: 128GB DDR4
- **Storage**: 1TB NVMe SSD
- **Network**: Fixed IP with high-speed connection
- **OS**: Ubuntu 22.04 LTS

**Performance Targets:**
- Support 10,000+ concurrent users
- Handle 100,000+ funding program records
- Process 50,000+ matches per hour during peak season
- Maintain 99.9% uptime during January-March rush

### 4.2 Optimized Single-Server Architecture

```
Production Stack (Native Services for Maximum Performance):
â”œâ”€â”€ Load Balancer & Reverse Proxy
â”‚   â””â”€â”€ Nginx (native systemd service)
â”‚       â””â”€â”€ Unix sockets â†’ PM2 cluster
â”œâ”€â”€ Application Layer
â”‚   â””â”€â”€ PM2 Cluster (8-12 Node.js instances)
â”‚       â””â”€â”€ Node.js 20 LTS applications
â”œâ”€â”€ Connection Management
â”‚   â””â”€â”€ PgBouncer (transaction pooling)
â”‚       â””â”€â”€ PostgreSQL 15 (native install)
â”œâ”€â”€ Dual Redis Setup
â”‚   â”œâ”€â”€ Redis-Cache (port 6379, LRU eviction, no persistence)
â”‚   â””â”€â”€ Redis-Queue (port 6380, no eviction, AOF persistence)
â””â”€â”€ Monitoring & Backup
    â”œâ”€â”€ Prometheus + Grafana
    â”œâ”€â”€ pgBackRest (automated PostgreSQL backups)
    â””â”€â”€ SystemD service management
```

### 4.3 Frontend Architecture

**Technology Stack:**
```
Frontend Architecture:
â”œâ”€â”€ Framework: Next.js 14 (App Router)
â”œâ”€â”€ Language: TypeScript 5.x
â”œâ”€â”€ Styling: Tailwind CSS + Korean UI patterns
â”œâ”€â”€ State Management: Zustand (lightweight, TypeScript-first)
â”œâ”€â”€ Forms: React Hook Form + Zod validation
â”œâ”€â”€ Data Tables: TanStack Table v8
â”œâ”€â”€ Calendar: FullCalendar (deadline visualization)
â”œâ”€â”€ Charts: Recharts (dashboard analytics)
â”œâ”€â”€ PWA: next-pwa (offline capability)
â””â”€â”€ Fonts: Pretendard (optimized Korean web font)
```

### 4.4 Backend Architecture

**Technology Stack:**
```
Backend Architecture (Optimized for Single Server):
â”œâ”€â”€ Runtime: Node.js 20 LTS
â”œâ”€â”€ Process Manager: PM2 (cluster mode)
â”œâ”€â”€ Framework: Express.js + tRPC (type-safe APIs)
â”œâ”€â”€ ORM: Prisma (database management)
â”œâ”€â”€ Validation: Zod schemas (runtime validation)
â”œâ”€â”€ Authentication: Passport.js + JWT
â”œâ”€â”€ Job Queue: Bull (Redis-based background jobs)
â”œâ”€â”€ Scheduler: node-cron (automated scraping)
â”œâ”€â”€ File Upload: Multer â†’ local storage (high-performance)
â””â”€â”€ API Documentation: tRPC auto-generated types
```

### 4.5 Production Database Configuration

**PostgreSQL 15 Optimized Configuration:**
```sql
-- Performance Tuning for 128GB RAM + NVMe SSD
shared_buffers = 24GB                  -- Conservative start (19% of RAM)
effective_cache_size = 80GB            -- 62% of total RAM
work_mem = 64MB                        -- Safe per-operation limit
maintenance_work_mem = 2GB             -- For VACUUM, INDEX operations
max_connections = 200                  -- PgBouncer handles multiplexing

-- SSD Optimizations
random_page_cost = 1.1                 -- NVMe SSD performance
effective_io_concurrency = 256         -- NVMe can handle high concurrency
checkpoint_timeout = 15min             -- Longer checkpoint intervals
max_wal_size = 64GB                    -- Allow larger WAL for performance

-- Reliability & Backup
wal_compression = on                   -- Reduce I/O
archive_mode = on                      -- Enable point-in-time recovery
archive_command = 'pgbackrest archive-push %p'
```

**PgBouncer Configuration:**
```ini
# Connection Pooling (Critical for Performance)
[databases]
connect = host=localhost port=5432 dbname=connect

[pgbouncer]
listen_port = 6432
pool_mode = transaction                # Optimal for web applications
default_pool_size = 50                # 50 real PG connections
max_client_conn = 500                 # 500 app connections
server_lifetime = 3600                # Rotate connections hourly
```

### 4.6 Enhanced Data Acquisition Pipeline

**Complete NTIS Agency Coverage (19 Agencies):**

#### Tier 1: Critical Agencies (3x Daily - Peak Performance)
| Agency | Ministry | Budget Share | Scraping Schedule |
|--------|----------|--------------|-------------------|
| í•œêµ­ì—°êµ¬ìž¬ë‹¨ (NRF) | ê³¼ê¸°ì •í†µë¶€/êµìœ¡ë¶€ | ~35% | 9:30 AM, 2:00 PM, 5:30 PM |
| ì •ë³´í†µì‹ ê¸°íší‰ê°€ì› (IITP) | ê³¼ê¸°ì •í†µë¶€ | ~15% | 9:30 AM, 2:00 PM, 5:30 PM |
| í•œêµ­ì‚°ì—…ê¸°ìˆ í‰ê°€ê´€ë¦¬ì› (KEIT) | ì‚°ì—…í†µìƒìžì›ë¶€ | ~12% | 9:30 AM, 2:00 PM, 5:30 PM |
| ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì› (TIPA) | ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ | ~8% | 9:30 AM, 2:00 PM, 5:30 PM |

#### Tier 2: Major Specialized Agencies (2x Daily)
| Agency | Ministry | Focus Area | Scraping Schedule |
|--------|----------|------------|-------------------|
| í•œêµ­ë³´ê±´ì‚°ì—…ì§„í¥ì› (KHIDI) | ë³´ê±´ë³µì§€ë¶€ | Healthcare/Biotech | 10:00 AM, 4:00 PM |
| í•œêµ­ì½˜í…ì¸ ì§„í¥ì› (KOCCA) | ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€ | Content/Media Tech | 10:00 AM, 4:00 PM |
| í•œêµ­í™˜ê²½ì‚°ì—…ê¸°ìˆ ì› (KEITI) | í™˜ê²½ë¶€ | Green Technology | 10:00 AM, 4:00 PM |
| ë†ë¦¼ì‹í’ˆê¸°ìˆ ê¸°íší‰ê°€ì› (IPET) | ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€ | AgTech/Food Tech | 10:00 AM, 4:00 PM |
| êµ­í† êµí†µê³¼í•™ê¸°ìˆ ì§„í¥ì› (KAIA) | êµ­í† êµí†µë¶€ | Construction/Transport | 10:00 AM, 4:00 PM |

#### Tier 3: Specialized Agencies (Daily)
| Agency | Ministry | Focus Area | Scraping Schedule |
|--------|----------|------------|-------------------|
| í•´ì–‘ìˆ˜ì‚°ê³¼í•™ê¸°ìˆ ì§„í¥ì› (KIMST) | í•´ì–‘ìˆ˜ì‚°ë¶€ | Maritime Technology | 10:30 AM |
| êµ­ë°©ê¸°ìˆ í’ˆì§„í¥ì—°êµ¬ì†Œ (KRIT) | ë°©ìœ„ì‚¬ì—…ì²­ | Defense Technology | 10:30 AM |
| êµ­ë°©ê¸°ìˆ í’ˆì§ˆì› (DTaQ) | ë°©ìœ„ì‚¬ì—…ì²­ | Defense Quality | 10:30 AM |
| ì§ˆë³‘ê´€ë¦¬ì²­ (KDCA) | ì§ˆë³‘ê´€ë¦¬ì²­ | Disease Control | 10:30 AM |
| ì‹í’ˆì˜ì•½í’ˆì•ˆì „ì²˜ (MFDS) | ì‹í’ˆì˜ì•½í’ˆì•ˆì „ì²˜ | Food/Drug Safety | 10:30 AM |

#### Tier 4: Niche Agencies (3x Weekly)
| Agency | Ministry | Focus Area | Scraping Schedule |
|--------|----------|------------|-------------------|
| í•œêµ­ìž„ì—…ì§„í¥ì› (KOFPI) | ì‚°ë¦¼ì²­ | Forestry Technology | Mon, Wed, Fri 11:00 AM |
| í•œêµ­ê¸°ìƒì‚°ì—…ê¸°ìˆ ì› (KMITI) | ê¸°ìƒì²­ | Weather Technology | Mon, Wed, Fri 11:00 AM |
| êµ­ë¦½ë¬¸í™”ìœ ì‚°ì—°êµ¬ì› (NRICH) | êµ­ê°€ìœ ì‚°ì²­ | Cultural Heritage | Mon, Wed, Fri 11:00 AM |
| ë†ì´Œì§„í¥ì²­ (RDA) | ë†ì´Œì§„í¥ì²­ | Agricultural Research | Mon, Wed, Fri 11:00 AM |

### 4.7 Intelligent Scraping Infrastructure

```javascript
// Enhanced Scraping Configuration
const scrapingConfig = {
  // Tiered scheduling for optimal resource usage
  tiers: {
    tier1: {
      agencies: ['nrf', 'iitp', 'keit', 'tipa'],
      schedule: '30 9,14,17 * * *',  // 3x daily
      timeout: 30000,
      retryAttempts: 3,
      priority: 'critical'
    },
    tier2: {
      agencies: ['khidi', 'kocca', 'keiti', 'ipet', 'kaia'],
      schedule: '0 10,16 * * *',  // 2x daily
      timeout: 25000,
      retryAttempts: 2,
      priority: 'high'
    },
    tier3: {
      agencies: ['kimst', 'krit', 'dtaq', 'kdca', 'mfds'],
      schedule: '30 10 * * *',  // Daily
      timeout: 20000,
      retryAttempts: 2,
      priority: 'medium'
    },
    tier4: {
      agencies: ['kofpi', 'kmiti', 'nrich', 'rda'],
      schedule: '0 11 * * 1,3,5',  // Mon, Wed, Fri
      timeout: 20000,
      retryAttempts: 1,
      priority: 'low'
    }
  },

  // Peak Season Enhancement (January-March)
  peakSeasonConfig: {
    enabled: true,
    months: [1, 2, 3],
    frequencyMultiplier: 1.5,  // 50% more frequent
    monitoringLevel: 'maximum'
  },

  // Intelligent Change Detection
  changeDetection: {
    contentHashing: true,
    semanticAnalysis: true,
    urgencyClassification: true,
    alertThresholds: {
      newAnnouncement: 'immediate',
      deadlineChange: 'critical',
      budgetChange: 'high'
    }
  }
};
```

### 4.8 Enhanced Monitoring & Alerting

```javascript
// Production Monitoring Stack
const monitoringStack = {
  metrics: {
    prometheus: {
      nodeExporter: true,
      postgresExporter: true,
      redisExporter: true,
      customAppMetrics: true
    },
    grafana: {
      dashboards: [
        'System Performance',
        'Database Health',
        'Application Metrics',
        'Scraping Success Rates',
        'User Activity'
      ]
    }
  },

  alerting: {
    critical: {
      tier1AgencyFailure: 'immediate_notification',
      databaseConnectionLoss: 'immediate_escalation',
      systemMemoryUsage: '>90%',
      diskSpaceUsage: '>85%'
    },
    warning: {
      scrapingDelays: '>5_minutes',
      slowQueries: '>1_second',
      highErrorRate: '>1%'
    }
  },

  logging: {
    structured: true,
    levels: ['error', 'warn', 'info', 'debug'],
    retention: '90_days',
    searchable: true
  }
};
```

---

## 5. Development & Deployment Workflow

### 5.1 Development Environment (MacBook M4 Max)

**Development Specifications:**
- **Hardware**: MacBook Pro M4 Max 16" (128GB RAM, 2TB SSD)
- **OS**: macOS Tahoe (latest)
- **Architecture**: ARM64 (M4 Max chip)

**Development Stack:**
```bash
# Development Environment Setup
Node.js 20 LTS (via nvm)
PostgreSQL 15 (Docker for development)
Redis 7 (Docker for development)
Git with GitHub integration
VS Code with TypeScript/Prisma extensions
```

### 5.2 Cross-Platform Build Strategy

```bash
# Build Process (handles ARM â†’ x86 transition)
#!/bin/bash
# build-for-production.sh

echo "ðŸ”¨ Building Connect for Linux x86_64..."

# 1. Run comprehensive tests
npm run test
npm run test:e2e
npm run lint
npm run type-check

# 2. Build production JavaScript (platform-agnostic)
NODE_ENV=production npm run build

# 3. Create deployment package (excluding native modules)
tar -czf connect-deployment.tar.gz \
  .next \
  public \
  package.json \
  package-lock.json \
  prisma \
  server.js \
  ecosystem.config.js \
  --exclude=node_modules

echo "ðŸ“¦ Deployment package ready: connect-deployment.tar.gz"
```

### 5.3 Atomic Deployment Pipeline

```bash
#!/bin/bash
# deploy-to-production.sh

set -euo pipefail

# Configuration
SERVER_IP="your.fixed.ip.address"
SERVER_USER="connect"
BASE_PATH="/opt/connect"
TIMESTAMP=$(date -u +%Y%m%dT%H%M%SZ)

echo "ðŸš€ Deploying Connect v7.0 to production..."

# 1. Upload deployment package
echo "ðŸ“¤ Transferring deployment package..."
scp connect-deployment.tar.gz $SERVER_USER@$SERVER_IP:$BASE_PATH/

# 2. Deploy with zero downtime
ssh $SERVER_USER@$SERVER_IP bash -s << 'DEPLOY_SCRIPT'
set -euo pipefail

BASE="/opt/connect"
TIMESTAMP=$(date -u +%Y%m%dT%H%M%SZ)
RELEASE_DIR="$BASE/releases/$TIMESTAMP"

# Create release directory
mkdir -p $RELEASE_DIR
cd $RELEASE_DIR

# Extract and prepare
tar -xzf $BASE/connect-deployment.tar.gz
rm $BASE/connect-deployment.tar.gz

# Install production dependencies for x86_64
npm ci --production --no-audit

# Run database migrations via PgBouncer
DATABASE_URL="postgresql://connect@localhost:6432/connect" \
  npx prisma migrate deploy

# Health check new version before switching
echo "ðŸ” Health checking new deployment..."
PORT=3001 pm2 start ecosystem.config.js --name health-check
sleep 10
curl -f http://localhost:3001/api/health || {
  pm2 delete health-check
  exit 1
}
pm2 delete health-check

# Atomic switch (zero downtime)
echo "ðŸ”„ Switching to new version..."
ln -sfn $RELEASE_DIR $BASE/current

# Reload PM2 cluster
pm2 reload ecosystem.config.js

# Cleanup old releases (keep 5 most recent)
cd $BASE/releases
ls -t | tail -n +6 | xargs -r rm -rf

echo "âœ… Deployment complete!"
DEPLOY_SCRIPT

echo "ðŸŽ‰ Connect v7.0 deployed successfully!"
```

### 5.4 Production Service Configuration

**PM2 Ecosystem Configuration:**
```javascript
// ecosystem.config.js
module.exports = {
  apps: [{
    name: 'connect',
    script: './server.js',
    instances: 'max',  // Use all available cores
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'production',
      PORT: 0,  // Use Unix socket
      SOCKET_PATH: '/run/connect.sock'
    },
    node_args: '--max-old-space-size=2048',
    max_memory_restart: '3G',
    out_file: '/opt/connect/logs/out.log',
    error_file: '/opt/connect/logs/error.log',
    merge_logs: true,
    time: true,
    kill_timeout: 10000,
    wait_ready: true,
    listen_timeout: 10000
  }]
};
```

**SystemD Service Management:**
```ini
# /etc/systemd/system/connect.service
[Unit]
Description=Connect Platform (PM2-managed)
After=network.target postgresql.service redis.service

[Service]
Type=forking
User=connect
Environment=PATH=/usr/local/bin:/usr/bin:/bin
Environment=PM2_HOME=/home/connect/.pm2
ExecStart=/usr/local/bin/pm2 resurrect
ExecReload=/usr/local/bin/pm2 reload all
ExecStop=/usr/local/bin/pm2 kill
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
```

### 5.5 Production Nginx Configuration

```nginx
# /etc/nginx/sites-available/connect
upstream connect_backend {
    server unix:/run/connect.sock;
    keepalive 64;
}

# HTTP â†’ HTTPS redirect
server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

# HTTPS production server
server {
    listen 443 ssl http2;
    server_name your-domain.com;

    # SSL configuration (via certbot)
    ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;

    # Security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;

    # Health check endpoint
    location /api/health {
        proxy_pass http://connect_backend;
        proxy_set_header Connection "";
        access_log off;
    }

    # API endpoints with rate limiting
    location /api/ {
        limit_req zone=api_limit burst=200 nodelay;
        proxy_pass http://connect_backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Static assets
    location /_next/static/ {
        proxy_pass http://connect_backend;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # All other requests
    location / {
        proxy_pass http://connect_backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

---

## 6. Enhanced Security & Compliance

### 6.1 Production Security Framework

```bash
# Security Hardening Checklist
# 1. SSH Configuration
PasswordAuthentication no
PubkeyAuthentication yes
PermitRootLogin no
AllowUsers connect

# 2. Firewall Configuration (ufw)
ufw allow 22/tcp     # SSH
ufw allow 80/tcp     # HTTP
ufw allow 443/tcp    # HTTPS
ufw deny 5432/tcp    # PostgreSQL (local only)
ufw deny 6379/tcp    # Redis (local only)
ufw enable

# 3. fail2ban Configuration
[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log
maxretry = 3
bantime = 3600

[nginx-req-limit]
enabled = true
filter = nginx-req-limit
action = iptables-multiport[name=ReqLimit, port="http,https", protocol=tcp]
logpath = /var/log/nginx/error.log
findtime = 600
bantime = 7200
maxretry = 10
```

### 6.2 PIPA Compliance Implementation

```javascript
// Privacy Protection Framework
const privacyFramework = {
  dataMinimization: {
    collectOnlyNecessary: true,
    purposeLimitation: true,
    retentionPeriods: {
      userProfiles: '7_years',  // Legal requirement
      activityLogs: '2_years',
      sessionData: '30_days'
    }
  },

  consentManagement: {
    granularConsent: true,
    easyWithdrawal: true,
    consentLogging: true,
    cookieConsent: true
  },

  dataRights: {
    accessRequests: 'within_10_days',
    correctionRequests: 'within_5_days',
    deletionRequests: 'within_3_days',
    portabilityRequests: 'json_export'
  },

  security: {
    encryption: {
      atRest: 'AES-256-GCM',
      inTransit: 'TLS-1.3',
      sensitiveFields: ['business_registration_number', 'contact_info']
    },
    accessControl: 'RBAC',
    auditLogging: 'all_data_access'
  }
};
```

---

## 7. Pricing Strategy (Unchanged)

### 7.1 Tier Structure

| Plan | Monthly Price | Annual Price | Target User |
|------|--------------|--------------|-------------|
| **Free** | â‚©0 | â‚©0 | Individual researchers exploring opportunities |
| **Pro** | â‚©9,900 | â‚©8,900/mo | Active grant seekers and small teams |
| **Team** | â‚©29,900 | â‚©24,900/mo | Organizations with multiple users |
| **Enterprise** | Custom | Custom | Large organizations (universities, major institutes) |

### 7.2 Feature Matrix

| Feature | Free | Pro | Team | Enterprise |
|---------|------|-----|------|------------|
| Funding Matches | 3/month | Unlimited | Unlimited | Unlimited |
| Agency Coverage | All 19 agencies | All 19 agencies | All 19 agencies | All 19 agencies |
| Data Freshness | Daily | Real-time | Real-time | Real-time |
| Match Explanations | Summary only | Detailed | Detailed + Scoring | Full Analysis |
| Partner Search | 5/month | 50/month | Unlimited | Unlimited |
| Warm Introductions | 0 | 5/month | 15/month | Custom |
| Collaboration Workspaces | 1 | 3 | 10 | Unlimited |
| API Access | No | Read-only | Full | Full + Webhooks |
| Support | Community | Email <24h | Priority | Dedicated Manager |

---

## 8. Success Metrics & KPIs

### 8.1 Enhanced Success Metrics

**Data Quality Metrics:**
- **Agency Coverage**: 100% of NTIS agencies (19/19 active)
- **Data Freshness**: < 6 hours from announcement to platform
- **Scraping Reliability**: > 99.5% successful scrapes
- **Match Accuracy**: > 95% user satisfaction with matches

**Platform Performance:**
- **Response Time**: < 200ms API response (P95)
- **Match Generation**: < 3 seconds for top 5 results
- **System Uptime**: > 99.9% during peak season
- **Concurrent Users**: Support 10,000+ simultaneous users

**Business Impact:**
- **User Growth**: 3,500 registered organizations by Month 6
- **Revenue**: â‚©120M+ ARR by end of Year 1
- **Success Stories**: 100+ successful funding applications
- **Network Effects**: 500+ active collaboration workspaces

---

## 9. Launch Strategy & Timeline

### 9.1 Enhanced Go-to-Market Timeline

**Phase 1: Beta Launch (December 1-14, 2024)**
- Closed beta: 10 partner organizations per agency tier
- Open beta: 100 organizations across all 3 types
- Complete 19-agency data integration testing
- Performance testing under simulated peak load

**Phase 2: Production Launch (December 15, 2024)**
- Public availability with full 19-agency coverage
- Real-time data pipeline fully operational
- Marketing campaign highlighting complete coverage advantage
- Customer success program activation

**Phase 3: Peak Season Excellence (January-March 2025)**
- 3x daily monitoring for Tier 1 agencies
- 24/7 technical support during application deadlines
- Daily data quality audits
- Proactive customer outreach for high-priority opportunities

### 9.2 Week 1-8 Implementation Schedule

| Week | Focus | Key Deliverables |
|------|-------|------------------|
| **Week 1-2** | Foundation & Infrastructure | - Server setup and configuration<br>- Database schema with 19 agencies<br>- Basic scraping infrastructure |
| **Week 3-4** | Core Features & Data Pipeline | - Funding match engine<br>- Tier 1-4 scraping implementation<br>- User registration and profiles |
| **Week 5-6** | Advanced Features | - Collaboration tools<br>- Notification system<br>- Payment integration |
| **Week 7-8** | Production Readiness | - Performance optimization<br>- Security hardening<br>- Monitoring setup<br>- Launch preparation |

---

## 10. Risk Management & Mitigation

### 10.1 Enhanced Risk Assessment

**Technical Risks:**
- **Single Point of Failure**: Mitigated by robust backup systems and monitoring
- **Peak Season Load**: Addressed with optimized single-server architecture
- **Data Accuracy**: Solved with multi-tier scraping and validation
- **Security Breaches**: Prevented with comprehensive security framework

**Business Risks:**
- **Competition**: Differentiated by complete agency coverage and fresh data
- **Seasonal Revenue**: Balanced with collaboration and tech transfer features
- **Government Relations**: Managed through compliance and value demonstration

### 10.2 Contingency Plans

**Technical Contingencies:**
- Automated failover procedures
- Rapid deployment rollback capability
- Emergency communication protocols
- Backup data sources for critical agencies

**Business Contingencies:**
- Extended free trial during peak season
- Strategic partnerships with tech centers
- International expansion planning
- Alternative revenue streams (premium services)

---

## 11. Competitive Advantage Summary

### 11.1 Enhanced Value Propositions

1. **Complete Agency Coverage**: Only platform covering all 19 NTIS agencies
2. **Real-Time Data**: Multi-daily updates vs. daily/weekly competitors
3. **Production-Grade Performance**: Optimized single-server architecture
4. **Transparent Matching**: Explainable results vs. black-box AI
5. **Korean Specialization**: Purpose-built for Korean R&D ecosystem
6. **Cost Efficiency**: â‚©9,900 vs â‚©28,000 for AI alternatives
7. **Complete Lifecycle**: Funding â†’ Collaboration â†’ Tech Transfer

### 11.2 Sustainable Competitive Moats

**Data Moat:**
- Comprehensive 19-agency scraping infrastructure
- Real-time data pipeline with intelligent change detection
- Historical success patterns and user behavior data
- Proprietary matching algorithms optimized for Korean context

**Network Moat:**
- Cross-organization type connections (Company â†” Institute â†” University)
- Warm introduction success history and reputation systems
- Collaboration project outcomes and partner recommendations
- User-generated content and success stories

**Technical Moat:**
- High-performance single-server architecture
- Production-grade security and compliance
- Korean-optimized user experience and workflows
- Deep integration with local systems and processes

---

## Conclusion

Connect v7.0 represents a production-ready, high-performance platform optimized for Korea's R&D ecosystem. With comprehensive coverage of all 19 NTIS commissioning agencies, real-time data collection, and a robust single-server architecture, Connect is positioned to become the definitive platform for Korean innovation funding and collaboration.

The platform's success will be measured by:
1. **Complete Coverage**: All Korean R&D opportunities in one place
2. **Data Freshness**: Real-time updates during critical application periods
3. **Performance Excellence**: Sub-second response times supporting 10,000+ users
4. **Network Effects**: Successful facilitation of meaningful R&D collaborations

With the foundation established in this PRD v7.0, Connect is ready for immediate development and December 2024 launch.

---

**Document Status**: Production Ready for Implementation
**Next Steps**: Begin infrastructure setup, implement Tier 1 agency scraping, initiate beta testing program
**Target Launch**: December 15, 2024

*End of PRD v7.0*