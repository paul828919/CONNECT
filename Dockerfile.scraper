# ===========================================
# Connect Platform - Scraper Dockerfile
# Playwright-enabled scraping service
# ===========================================
# Using ubuntu:20.04 base instead of Playwright base image to avoid
# duplicate browser installations (base image v1.48.0 vs npm v1.56.1)

FROM ubuntu:20.04

# Prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive

WORKDIR /app

# Install system dependencies including Node.js 20, Python, Tesseract OCR, Korean fonts
# Using UTC as standard for all backend services (frontend handles KST display)
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        curl \
        ca-certificates \
        gnupg && \
    curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y --no-install-recommends \
        nodejs \
        tesseract-ocr \
        tesseract-ocr-kor \
        fonts-nanum \
        fonts-nanum-extra \
        python3-pip \
        python3-dev \
        libxml2-dev \
        libxslt-dev \
        build-essential \
        tzdata && \
    ln -sf /usr/share/zoneinfo/UTC /etc/localtime && \
    echo "UTC" > /etc/timezone && \
    dpkg-reconfigure -f noninteractive tzdata && \
    pip3 install --no-cache-dir pyhwp six && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Copy package files
COPY package.json package-lock.json ./

# Install dependencies (including Playwright npm package)
RUN npm ci --only=production

# Set Playwright browsers path to a shared location accessible by all users
ENV PLAYWRIGHT_BROWSERS_PATH=/ms-playwright

# Install Playwright Chromium browser with system dependencies
# This installs ONLY the browser version matching the npm package (v1.56.1)
# --with-deps ensures all required system libraries are installed
RUN npx playwright install chromium --with-deps && \
    chmod -R 755 /ms-playwright && \
    rm -rf /var/lib/apt/lists/* && \
    apt-get clean

# Install tsx for TypeScript runtime
RUN npm install -g tsx

# Copy application code
COPY lib ./lib
COPY prisma ./prisma
COPY tsconfig.json ./tsconfig.json
COPY scripts ./scripts

# Generate Prisma Client
RUN npx prisma generate

# Copy entrypoint script (before USER switch for proper permissions)
COPY docker-entrypoint-scraper.sh ./
RUN chmod +x docker-entrypoint-scraper.sh

# Create non-root user with home directory
RUN useradd --system --uid 1001 --create-home scraper && \
    mkdir -p /app/logs /app/data /home/scraper/.cache /home/scraper/.config && \
    chown -R scraper:scraper /app /home/scraper

# Switch to non-root user
USER scraper

# Environment
ENV NODE_ENV=production
ENV PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=0

# Health check - verify scraper service is responsive
HEALTHCHECK --interval=60s --timeout=10s --start-period=60s --retries=3 \
  CMD pgrep -f "tsx lib/scraping/index.ts" > /dev/null || exit 1

# Use entrypoint for container initialization
ENTRYPOINT ["/app/docker-entrypoint-scraper.sh"]
