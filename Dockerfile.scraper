# ===========================================
# Connect Platform - Scraper Dockerfile
# Playwright-enabled scraping service
# ===========================================

FROM mcr.microsoft.com/playwright:v1.48.0-focal

WORKDIR /app

# Install Node.js 20, Python pip, Tesseract OCR, pyhwp, and Korean fonts
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y nodejs && \
    apt-get install -y --no-install-recommends \
        tesseract-ocr \
        tesseract-ocr-kor \
        fonts-nanum \
        fonts-nanum-extra \
        python3-pip \
        python3-dev \
        libxml2-dev \
        libxslt-dev \
        build-essential && \
    pip3 install --no-cache-dir pyhwp six && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Copy package files
COPY package.json package-lock.json ./

# Install dependencies (including Playwright)
RUN npm ci --only=production

# Install tsx for TypeScript runtime
RUN npm install -g tsx

# Copy application code
COPY lib ./lib
COPY prisma ./prisma
COPY tsconfig.json ./tsconfig.json
COPY scripts ./scripts

# Generate Prisma Client
RUN npx prisma generate

# Copy entrypoint script (before USER switch for proper permissions)
COPY docker-entrypoint-scraper.sh ./
RUN chmod +x docker-entrypoint-scraper.sh

# Create non-root user with home directory for LibreOffice
RUN useradd --system --uid 1001 --create-home scraper && \
    mkdir -p /app/logs /app/data /home/scraper/.cache /home/scraper/.config && \
    chown -R scraper:scraper /app /home/scraper

# Switch to non-root user
USER scraper

# Environment
ENV NODE_ENV=production
ENV PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=0

# Health check - verify scraper worker is responsive
# Check if the worker process is running
HEALTHCHECK --interval=60s --timeout=10s --start-period=60s --retries=3 \
  CMD pgrep -f "tsx lib/scraping/worker.ts" > /dev/null || exit 1

# Use entrypoint for container initialization
ENTRYPOINT ["/app/docker-entrypoint-scraper.sh"]